\documentclass[a4paper, 11pt]{report}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{a4wide}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{appendix}
\usepackage{color}
\definecolor{darkblue}{rgb}{0,0,0.6}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=darkblue,          % color of internal links
    citecolor=darkblue,        % color of links to bibliography
    filecolor=darkblue,      % color of file links
    urlcolor=darkblue           % color of external links
}
\usepackage{subfigure}

\usepackage{listings}
\lstset{ %
language={},                % choose the language of the code
basicstyle=\tiny,       % the size of the fonts that are used for the code
%numbers=left,                   % where to put the line-numbers
%numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
%stepnumber=2,                   % the step between two line-numbers. If it's 1 each line will be numbered
%numbersep=5pt,                  % how far the line-numbers are from the code
backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,	                % adds a frame around the code
tabsize=4,	                % sets default tabsize to 2 spaces
%captionpos=b,                   % sets the caption-position to bottom
breaklines=true,                % sets automatic line breaking
breakatwhitespace=true,        % sets if automatic breaks should only happen at whitespace
title=\lstname,                 % show the filename of files included with \lstinputlisting; also try caption instead of title
escapeinside={\%*}{*)},          % if you want to add a comment within your code
aboveskip=1pt,
belowskip=5pt
}
\usepackage{algorithm}
\usepackage{algorithmic}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

\begin{titlepage}

\begin{center}

\begin{figure}
\centering
\mbox{\subfigure{\includegraphics[width=4cm]{ulg.pdf}}
\hspace{6cm}
\subfigure{\includegraphics[width=4cm]{sciencesappli}}}
\end{figure}

\ \\[1cm]

\textbf{\large ATFE0015-1 - Travail de fin d'études}\\[1,5cm]




\huge Intérêt du calcul distribué pour l'optimisation à l'aide d'algorithmes évolutionnaires
\HRule \\[0.4cm]
\includegraphics[width=5cm]{img/evo.png}


\vfill

\large
\emph{Auteur:}\\
Arnaud \textsc{Schoofs}\\
\href{mailto:arnaud.schoofs@gmail.com}{arnaud.schoofs@gmail.com}\\
\large $2^{\textnormal{ème}}$ année du grade de master en ingénieur civil en informatique,\\
à finalité approfondie \\[1cm]

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Superviseurs:}\\
Louis \textsc{Wehenkel}\\
Francis \textsc{Maes}
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Jury:} \\
Louis \textsc{Wehenkel}\\
Guy \textsc{Leduc}\\
Pierre \textsc{Geurts}\\
Francis \textsc{Maes}
\end{flushright}
\end{minipage}

\ \\[1cm]

{\large \today}

\end{center}
\end{titlepage}

\newpage
\tableofcontents
\newpage

\chapter{Introduction et objectifs}

\section{Introduction}
\label{intro}
Dans de nombreux domaines scientifiques la demande en puissance de calcul devient de plus en plus importante. Pour répondre à cette demande sont apparus les super-calculateurs, les grilles de calcul et le calcul distribué.
% TODO preuve d'implications ?

Personnellement, j'ai découvert le concept de calcul distribué, et plus précisément de calcul volontaire, le 28/02/2008 grâce à un article publié sur un site informatique~\cite{MACG}. J'ai rapidement été séduit par le concept et me suis fortement impliqué au sein de la communauté des volontaires de l'\textit{L'Alliance Francophone}~\cite{AF}. Arrivé en deuxième année de Master en ingénieur civil en informatique, il m'a semblé intéressant d'étudier l'intérêt que pourrait avoir le calcul volontaire pour les chercheurs de l'université de Liège. 

Actuellement, les solutions privilégiées au sein de l'\textit{Institut Montefiore} sont l'utilisation d'ordinateurs très puissant (e.g. 24 cores @ 1.9GHz avec 24Go de RAM), l'utilisation du super-calculateur NIC3 et l'utilisation d'une petite grille de calcul au sein de l'institut. Le calcul distribué volontaire se présente comme une alternative à ces trois solutions.
% TODO comparer les GFLOPS

Afin de mener à bien ce projet, un sujet de recherche était nécessaire. Après divers contacts avec le corps enseignant, les recherches de F. \textsc{Maes} et J. \textsc{Becker} et L. \textsc{Wehenkel} concernant l'annotation de protéines grâce à des méthodes d'apprentissage ont semblées bien adaptées à ce nouveau paradigme de calcul~\cite{POSTER}\cite{CAP}. Le travail réalisé vise à optimiser les algorithmes d'apprentissage utilisé dans le cadre de l'étude des protéines.

\section{Objectifs}
\label{objectifs}
Comme mentionné dans la section~\ref{intro}, l'objectif premier de ce travail est de mettre en place un serveur de calcul distribué permettant de fournir une solution alternative aux solutions actuellement utilisées par les chercheurs de l'\textit{Institut Montefiore} lorsque la demande en temps de calcul est très importante. A ce titre, le travail vise également à mettre en avant les avantages et inconvénients de la méthode proposée.

Un autre objectif du travail est de se familiariser avec les algorithmes d'apprentissage de type évolutionnaires dans le cadre de l'optimisation et d'implémenter des algorithmes de ce type adaptés au cadre de recherche fixé.

Il est important de distinguer dès maintenant les réalisations principales de ce travail: % TODO ref section
\begin{itemize}
\item Une réalisation très pratique: la mise en place du serveur de calcul distribué, son maintien et sa promotion. Cet aspect requiert des connaissances pratiques très variées dans le domaine de l'informatique. Il s'agit ici d'une réalisation assimilable au travail d'un administrateur réseau.
\item Une réalisation plus théorique: la compréhension des algorithmes évolutionnaires à estimation de distribution et l'implémentation d'un algorithme de ce type. Ce travail présente en particulier un algorithme de type EDA original plus adapté au calcul distribué que les EDA classiques. %TODO ref
Il s'agit ici d'un travail de recherche plus conventionnel comprenant les trois phases habituelles que sont: la prise de connaissance de l'état de l'art, la développement d'une solution originale et la réalisation de tests visant à juger la qualité de la solution proposée.
\item Une réalisation de génie logiciel: l'intégration des algorithmes développés au sein de la plate-forme de calcul distribué. 
\end{itemize}

%\section{Structure de ce rapport}
%TODO

%Dans la suite de ce rapport, un chapitre sera consacré à chacune de ces réalisations. % TODO section

%Une partie très importante du travail a bien entendu été consacrée à l'intégration des algorithmes évolutionnaires au sein de la plate-forme de calcul distribué. Deux solutions ont été envisagées. La première est une sorte de prototype dont l'objectif premier était de servir de \textit{proof of concept}. Cette première solution sera abordée dans ce rapport mais pas détaillée (). %TODO section

%
%Comme souvent en recherche, partant de ces deux objectifs bien définis, de nouveaux objectifs secondaires sont venus s'ajouter petit à petit durant la réalisation du travail en fonction des résultats obtenus. Ceux-ci seront détaillés au fur et à mesure dans ce rapport. En particulier, la solution proposée étant très prometteuse, des recherches approfondies en la matière sont nécessaires. C'est pourquoi un objectif du travail, et plus précisément de ce rapport, est de fourni un document aussi complet et compréhensible que possible afin que le travail de recherche puisse être continué à partir de cette base. Dans la même optique, la suite de ce rapport montrera qu'une partie importante du travail réalisé a été consacrée à l'intégration de la solution proposée au sein des recherches de F. \textsc{Maes} afin de faciliter les recherches en la matière à moyen et à long terme. 

%\subsection{Rapport} % TODO meilleur titre
%% TODO mettre des ref vers les sections
%Dans ce rapport je commencerai par faire un bref rappel de ce qu'est le calcul distribué. Je présenterai ensuite l'architecture choisie pour le calcul volontaire dans le cadre de ce travail. Ensuite, chaque tâche réalisée pour la mise en oeuvre et l'implémentation sera décrite en suivant, dans la mesure du possible, l'ordre chronologique de réalisation. Enfin, les conclusions mettront en avant les avantages et inconvénients de la solution proposée et des propositions de recherche future seront proposées.
% % TODO étoffer 

\chapter{Contexte}

\section{Introduction}
Ce chapitre a pour but d'introduire le contexte dans lequel a été réalisé ce travail. Il s'articule en trois parties principales:
\begin{itemize}
\item Une présentation de ce qu'est le calcul distribué (section~\ref{calculdistribue}).
\item Une présentation de la plate-forme de calcul distribué utilisée (section~\ref{boincpresentation}).
\item Une présentation des recherches de F. \textsc{Maes}, J. \textsc{Becker} et L. \textsc{Wehenkel} concernant l'annotation de protéines \textit{via} des algorithmes d'apprentissage (section~\ref{proteines}).
\end{itemize}

\section{Le calcul distribué}
\label{calculdistribue}
\subsection{Introduction}
% TODO parler des différentes types et différentes architectures http://en.wikipedia.org/wiki/Distributed_computing#Models ?
% (mémoire partagée/distribuée, message passing etc)
En informatique, lorsque les calculs à effectuer demandent énormément de temps d'exécution, la tendance actuelle est de diviser le problème en plusieurs tâches aussi indépendantes les unes des autres que possible. Une fois le problème divisé en plusieurs unités de calcul, différents niveaux de parallèlisation sont possibles:
\begin{itemize}
\item Répartition au sein de plusieurs coeurs d'un même processeurs. % TODO nom
\item Répartition au sein de plusieurs processeurs d'une même machine. % TODO nom
\item Répartition au sein de plusieurs machines du même type faisant partie d'une infrastructure particulière, on parlera souvent de \textit{supercomputers}.
\item Répartition au sein de plusieurs machines hétérogènes faisant partie d'une infrastructure particulière, on parlera souvent de \textit{clusters} ou de \textit{soupercomputers}. % TODO vérifier
\item Répartition au sein de plusieurs machines hétérogènes ne faisant pas partie d'une infrastructure particulière, on parlera souvent de \textit{grid computing} ou de \textit{volunteer computing} (calcul volontaire). Le terme \textit{grid computing} étant plutôt destiné aux organisations qui partagent leurs ressources entre elles en suivant certaines règles afin d'atteindre un but commun, tandis que le terme \textit{volunteer computing} désigne plutôt le cas de figure où quiconque (ayant un accès au réseau) peut mettre à disposition une certaine puissance de calcul sur base volontaire.
\end{itemize}
C'est à cette dernière catégorie que s'intéresse principalement ce travail. 

\subsection{Le calcul volontaire}
\label{calculvolontaire}
Le calcul volontaire est une forme particulière de calcul distribué où des volontaires mettent à disposition du projet une certaine puissance de calcul. Les machines des volontaires peuvent être très variées et la seule réelle restriction pour participer est d'avoir un accès au réseau. 

Avant même de s'intéresser aux enseignements tirés de ce travail, il est important de remarquer que ce concept, bien que séduisant, possèdent certains désavantages par rapport à l'utilisation d'un super-calculateur par exemple~\cite{VOLUNTEER}.

En effet, les volontaires participent de manière bénévole et anonyme au projet et ne sont donc en aucune responsabilité vis à vis du projet. Il n'y a donc aucune garantie quant à la puissance de calcul délivrée. Ceci n'est en général pas vrai pour un super-calculateur où la puissance de calcul est fixe et connue. Il faut tout de même nuancer cette dernière remarque puisqu'en général une infrastructure telle qu'un super-calculateur est partagée par plusieurs équipes de chercheurs et que donc la puissance effectivement disponible peut varier.

Parallèlement à cela, les utilisateurs n'ayant aucune responsabilité vis à vis du projet, ceux-ci peuvent tout à fait renvoyer de faux résultats au serveur (intentionnellement ou non). C'est donc à l'administrateur du projet de se protéger contre ce genre de problématique.

A côté de ces inconvénients, il y a bien entendu certains avantages, le principal étant probablement le coût. En effet, les super-calculateurs coûtent en général très cher et tous les projets de recherche n'ont pas les moyens de se payer une telle infrastructure. Pour mettre en place un serveur de calcul distribué une machine standard peut déjà suffire ! Comme mentionné précédemment, l'aspect négatif et qu'il n'y a aucune garantie quant à la puissance de calcul. C'est le rôle de l'administrateur du projet de rendre celui-ci attractif. La communication avec les volontaires est donc un aspect à ne pas négliger. Dans la même optique, le projet doit inspirer la confiance car les volontaires doivent faire confiance au projet à différents points de vue:
\begin{itemize}
\item Les volontaires exécutent les applications fournies par le projet et doivent donc être convaincu que celles-ci ne sont nuisibles d'aucune façon. Ceux-ci préfèrent en général les projets dont le code source est public (au moins en partie).
\item Les volontaires doivent faire confiance à l'administrateur du projet quant aux mesures de sécurité mises en place afin de protéger le serveur. En effet, un serveur vulnérable pourrait être utilisé comme vecteur de transmission pour toutes sortes de \textit{malwares}.
\item Les volontaires doivent faire confiance au projet quant au sérieux des recherches effectuées et aux publications qui s'en suivent. Ceux-ci privilégient en général les projets dont les découvertes tombent dans le domaine public ce qui est tout à fait normal vu qu'elles ont été réalisées grâce au travail de bénévoles.
\end{itemize}
En résumé, dans le cadre de projets utilisant le calcul distribué la puissance de calcul ne s'achète pas avec de l'argent mais elle se mérite.

Enfin, un autre avantage du calcul volontaire est qu'il permet de sensibiliser le public aux recherches effectuées.

\section{\textsc{BOINC}: une plate-forme de calcul distribué}
\label{boincpresentation}
\subsection{Introduction}
Le but de cette section est de présenter la plate-forme de calcul distribué utilisée: \textsc{BOINC}. Les différents aspects qu'il faut maîtriser afin de mettre en place un serveur \textsc{BOINC} seront également abordés. Ceux-ci sont détaillés dans la documentation de \textsc{BOINC} fournie par l'université de \textit{Berkeley}~\cite{WIKI}.

\subsection{Le choix de \textsc{BOINC} comme plate-forme de calcul distribué}
\label{avantagesboinc}
% TODO qu'est ce qui se fait d'autre
Pour la réalisation de ce travail une plate-forme de calcul distribué existante a été utilisée: \textsc{BOINC}. Bien entendu, il aurait été possible de réaliser l'implémentation d'une plate-forme de calcul distribué "à partir d'une page blanche" mais ce n'est pas l'approche qui a été suivie pour plusieurs raisons.

La raison principale est que ce travail d'implémentation aurait pris un temps considérable et n'aurait donc pas permis de conférer à ce travail l'aspect "multi-facette" décrit dans la section~\ref{objectifs}. La travail aurait été un pur travail d'implémentation réseau, il n'aurait pas été possible de s'intéresser en plus à la problématique de l'optimisation à l'aide d'algorithmes évolutionnaires. De plus, pour qu'un projet de calcul volontaire soit fonctionnel il faut bien entendu des volontaires... Utiliser une plate-forme existante permet d'être directement en contact avec des volontaires potentiels.

C'est la plate-forme \textsc{BOINC} développée par l'université de \textit{Berkeley} qui a été retenue. Les raisons de ce choix sont multiples:
\begin{itemize}
\item La plateforme \textsc{BOINC} existe depuis plusieurs années et est stable.
\item Celle-ci est libre et de nombreux volontaires travaillent sans cesse à l'améliorer.
\item Des dizaines de projets scientifiques très variés utilisent la plate-forme \textsc{BOINC}. Cela va de la recherche d'une intelligence extraterrestre (SETI@home~\cite{SETI}), aux recherches contre le virus du sida (FightAIDS@home~\cite{FIGHTAIDS}), en passant par la recherche de nouveaux nombres premiers (PrimeGrid~\cite{PRIMEGRID}).
% TODO check chiffres
\item La communauté \textsc{BOINC} représente un nombre très importants de volontaires: 494671 machines pour 305398 volontaires représentant une moyenne de 5959,08 TFLOPS sur 24h~\cite{BOINC}. A titre comparatif, actuellement le super-calculateur le plus puissant au monde a une puissance effective de 2566 TFLOPS~\cite{TOP500}.
\item Mon implication dans le monde \textsc{BOINC}, et plus précisément au sein de l'\textit{Alliance Francophone}~\cite{AF}, depuis plusieurs années m'assurait un certain soutien des volontaires de cette communauté.
\item Les volontaires qui calculent sur le réseau \textsc{BOINC} reçoivent un certain nombre de crédits pour chaque unité calculée. Ces crédits ne représentent rien de concret mais ils engendrent une émulation importante au sein de la communauté: de nombreux sites présentent sous formes diverses et variées des statistiques par rapport à ces crédits, les utilisateurs se regroupent en équipe et organiser des compétitions entre eux (Fig.~\ref{fb}), ... En bref, ce système de crédits, bien que n'ayant aucun intérêt scientifique, permet de rendre la communauté très active et évite une certaine lassitude des utilisateurs.\label{credits}
\end{itemize}

\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{img/FB_Rosetta_total.png}
\caption{Formula Boinc: Rosetta@home~\cite{SEB}}
\label{fb}
\end{figure}


\subsection{Architecture et fonctionnement général}
La plateforme \textsc{BOINC} est basée sur une architecture client-serveur (Fig.~\ref{clientserveur}). Le serveur et le client sont disponibles gratuitement sur le site de \textit{Berkeley}~\cite{BOINC}.
\begin{figure}[!h]
\centering
\includegraphics[scale=0.4]{img/Boinc_arch.pdf}
\caption{\textsc{BOINC}: architecture client-serveur}
\label{clientserveur}
\end{figure}

Chaque projet scientifique désirant utiliser cette infrastructure déploie un serveur \textsc{BOINC} et publie l'adresse de celui-ci sur internet~\footnote{Plusieurs sites recensent l'ensemble des projets \textsc{BOINC}.}. % TODO exemples.
Les volontaires exécutent quant à eux l'application client, \textit{BOINC Manager}, sur leur(s) machine(s). Cette interface permet aux volontaires de rejoindre simplement n'importe quel projet en spécifiant simplement son URL (Fig.~\ref{boincmanager}). Ce programme est disponible sous forme de sources et sous forme binaire pour différentes plateformes (Windows, Linux, OS X, ...). Enfin, cette application permet de régler un ensemble de paramètres définissant la manière dont la machine sera utilisée pour calculer les unités de travail des projets (Fig.~\ref{boincpref}): pourcentage de CPU maximum alloué, quantité maximale de RAM utilisable, espace disque maximum utilisable, calcul en permanence vs. calcul quand l'utilisateur est inactif, utilisation réseau, ... Une fois ces paramètres réglés, l'application s'exécutant avec une priorité extrêmement faible, l'utilisateur ne se rend normalement même plus compte qu'il calcule pour des projets scientifiques!

\begin{figure}[!h]
\centering
\includegraphics[scale=0.35]{img/boincmanager.png}
\caption{\textit{Boinc Manager}}
\label{boincmanager}
\end{figure}

\begin{figure}[!h]
\centering
\includegraphics[scale=0.35]{img/boincpref.png}
\caption{\textsc{BOINC}: préférences utilisateur}
\label{boincpref}
\end{figure}

Le principe général de fonctionnement est assez simple: le serveur \textsc{BOINC} génère des \textit{Work Units} (WU) et le \textit{BOINC Manager}, installé sur les ordinateurs des volontaires, contacte périodiquement le serveur afin de récupérer des WU. Dès que ces WU sont calculées, le \textit{BOINC Manager} renvoie les résultats au serveur qui se charge de traiter ces résultats et de générer de nouvelles unités. 

Le fonctionnement du serveur est paramétrable à l'aide de fichiers XML de configuration (e.g. \textit{config.xml}). Le serveur repose principalement sur une base de données MySQL contenant toutes les informations nécessaires concernant les utilisateurs, les unités de travail, divers statistiques, ...

Comme expliqué précédemment, le serveur \textsc{BOINC} est fourni par l'université de \textit{Berkeley}, et il n'y a donc pas eu un travail trop important d'implémentation à réaliser afin de pouvoir distribuer des unités de travail. Cependant, afin de pouvoir utiliser ce serveur, il faut se familiariser avec son mode de fonctionnement et implémenter certains programmes auxiliaires utilisés par le serveur. En effet, tous les projets ne fonctionnent évidemment pas exactement de la même façon et il est donc logique que certaines parties du serveur doivent être adaptées selon les besoins du projet. Pour ce faire, l'université de \textit{Berkeley} maintient un wiki reprenant la documentation nécessaire à l'utilisation du serveur \textsc{BOINC} \cite{WIKI}.

\subsection{Les programmes auxiliaires}
\label{daemons}
Cette section vise à introduire les programmes qui doivent être développés pour mettre sur pied un serveur \textsc{BOINC} fonctionnel. Ceux-ci prennent la forme de \textit{daemons} et sont au nombre de trois (minimum): \textit{work generator}, \textit{validator}, \textit{assimilator}. 

Les implémentations réalisées seront décrites plus loin dans ce rapport. %TODO section
Cette section vise uniquement à introduire d'un point de vue fonctionnel ces programmes ainsi que les API permettant d'implémenter ceux-ci facilement.

\subsubsection{Work generator}
\label{workgeneratorboinc}
Il s'agit du programme qui génère les unités de travail (\textit{Jobs} ou \textit{Work Units}). Concrètement une unité de travail consiste souvent en un ensemble de fichiers \textit{input} et/ou de paramètres à passer en ligne de commande au programme exécuté chez le volontaire. 

L'implémentation du \textit{work generator} est réalisée en utilisant l'API \textsc{BOINC} ce qui facilite grandement l'ajout du/des \textit{job(s)} créé(s) dans la base de données du serveur \textsc{BOINC} afin que ceux-ci soient prêt à être envoyés aux volontaires.

Le serveur \textsc{BOINC} étant fourni avec un exemple de \textit{work generator}, l'implémentation de la partie \textsc{BOINC} du programme est facilement réalisée en se basant sur cet exemple (\textit{sample\_work\_generator.cpp}). Les étapes importantes du programme sont:
\begin{itemize}
\item Génération du ou des fichiers \textit{input}.
\item Placement des fichiers \textit{input} dans la hiérarchie de dossiers \textit{download} (via l'API \textsc{BOINC}). Les fichiers téléchargeables par l'utilisateur doivent impérativement se trouver dans le dossier \textit{download} du serveur. Ce dossier pouvant contenir des milliers de fichiers, l'API \textsc{BOINC} utilise une hiérarchie de dossiers où le nom du sous-dossier contenant un fichier est déterminé sur base du nom de ce fichier. Il s'agit d'une technique courante permettant de retrouver plus rapidement des fichiers lorsque ceux-ci sont nombreux au sein d'un répertoire.
\item Remplissage de la structure de données décrivant une unité de travail (\textit{DB\_WORKUNIT}). Cette structure contient entre autres: nom de l'unité, application client cible, divers paramètres décrivant les ressources susceptibles d'être utilisées pour le calcul de cette unité (mémoire RAM, temps CPU, ...).
\item Appel de la fonction \textit{create\_work()} de l'API \textsc{BOINC}. Cette fonction se charge de mettre toutes les informations concernant l'unité dans la base de données. Après cet appel, l'unité est prête à être téléchargée par un volontaire. Les arguments à passer à cette fonction sont principalement: la structure \textit{DB\_WORKUNIT}, le ou les noms des fichiers \textit{input} et les fichiers \textit{template} décrivant les noms et le nombres les fichiers \textit{input} et \textit{output} de l'unité de travail. % TODO plus d'info sur les templates
\end{itemize}

Les parties spécifique à une application sont principalement la génération des fichiers \textit{input} et les \textit{templates} \textit{input}/\textit{output} correspondant.

\subsubsection{Validator}
Les \textit{jobs} étant calculés par des volontaires, il est important d'implémenter une politique de validation des résultats renvoyés. En effet, certains ordinateurs des volontaires peuvent être overclocké à outrance engeandrant parfois des résultats erronés. Parallèlement à cela, vu le système de crédits mis en place au sein de \textsc{BOINC} (voir section ~\ref{credits}), certains utilisateurs pourraient être tentés de tricher en renvoyant volontairement de faux résultats. 

Généralement, un même \textit{job} sera envoyé au moins deux fois sur le réseau \textsc{BOINC}. C'est ce qu'on appelle le principe de réplication. Ceci permet de valider simplement des résultats en les comparant par exemple. L'implémentation du \textit{validator} passe donc par l'implémentation d'une fonction de comparaison des résultats. La configuration du serveur \textsc{BOINC} (et plus particulièrement du \textit{scheduler} qui distribue les unités) permet également de pousser la validation encore plus loin en imposant que les multiples instances d'un \textit{job} soient calculées par des machines différentes par exemple.

Concrètement, l'implémentation d'un \textit{validator} passe par l'implémentation de 3 fonctions:
\begin{verbatim}
extern int init_result(RESULT& result, void*& data)
extern int compare_results(RESULT& r1, void* data1, 
                           RESULT& r2, void* data2, bool& match)
extern int cleanup_result(RESULT& r, void* data)
\end{verbatim}

La première fonction prend en entrée un résultat ($result$), analyse d'une manière ou d'une autre les fichiers \textit{output} associés (ceux-ci sont accessibles via la structure $RESULT$) et crée une structure permettant de déterminer si deux résultats sont identiques sur base de cette structure uniquement. Un pointeur vers cette structure est alors retourné via le paramètre $data$. La valeur de retour de la fonction indique si l'opération s'est bien déroulée (0 en cas de succès, \textit{ERR\_OPENDIR} en cas d'erreur temporaire et toute autre valeur en cas d'erreur définitive).

La deuxième fonction prend en entrée deux résultats et leur structure de données associée (crée grâce à la méthode précédente) et retourne, via l'argument \textit{match}, si les deux résultats sont identiques ou pas\footnote{Le terme identique n'est pas à prendre au pied de la lettre. Deux résultats sont considérés comme "identiques" par rapport à l'application visée.}.

Enfin, la dernière fonction est appelée afin de libérer l'espace mémoire occupé par la structure de donnée \textit{data}.

Pour que le programme soit fonctionnel, ces fonctions doivent être liées avec les fichiers \textit{validator.cpp}, \textit{validate\_util.cpp} et \textit{validate\_util2.cpp} du serveur \textsc{BOINC}. Deux exemples de \textit{validator} sont fournis avec le code source ce qui facilite l'implémentation d'un \textit{validator} particulier (\textit{sample\_trivial\_validator.cpp} et \textit{sample\_bitwise\_validator.cpp}).

\subsubsection{Assimilator}
Le rôle de l'\textit{assimilator} est de traiter les résultats canoniques (i.e. les résultats ayant passé l'étape de validation). En effet, sauf spécification contraire, lorsqu'un \textit{job} a obtenu un résultat valide, celui-ci est, après un certain laps de temps, retiré de la base de données et ses fichiers associés sont supprimés du serveur. Le rôle de l'\textit{assimilator} est donc par exemple de stocker les résultats dans une base de données dédiée ou de stocker les résultats à un autre endroit du disque (ou sur une autre machine).

Concrètement, l'implémentation de ce programme est réalisée en implémentant la fonction:
\begin{verbatim}
int assimilate_handler(WORKUNIT& wu, vector<RESULT>& results, 
                       RESULT& canonical_result)
\end{verbatim}

Cette fonction est appelée dans 2 cas de figure:
\begin{itemize}
\item Un résultat canonique a été trouvé, i.e. le \textit{validator} a identifié un nombre suffisant de résultats identiques (généralement 2).
\item L'unité a été considérée comme invalide (trop de résultats indiquent une erreur ou trop de résultats différents).
\end{itemize}
La distinction entre ces deux cas est réalisée grâce au champ \textit{canonical\_resultid} de la structure \textit{WORKUNIT}. Dans le cas où un résultat canonique a été trouvé, la valeur de ce champ est non nulle et la référence \textit{canonical\_result} pointe vers le résultat canonique. Dans les deux cas de figure, le vecteur \textit{results} contient l'ensemble des résultats associés à l'unité de travail \textit{wu}.

Comme souvent, une valeur de retour égale à 0 indique un succès. La valeur spéciale \textit{DEFER\_ASSIMILATION} est utilisée pour différer l'assimilation. La fonction sera appelée à nouveau lorsqu'un autre résultat concernant cette unité sera disponible. Toutes les autres valeurs indiquent une erreur qui sera reportée dans les \textit{logs}.

%\subsection{Gestion des fichiers}
% TODO

\subsection{BOINC API vs. wrapper}
Habituellement les applications \textsc{BOINC} (i.e. les applications clients exécutées sur les machines des volontaires) sont codées en C++ et utilisent l'API \textsc{BOINC} afin de communiquer avec le \textit{BOINC Manager}. Cet API définit des fonctions d'initialisation et de terminaison devant être appelée en début et fin de programme, mais également des fonctions d'utilité plus pratique. Ainsi, la fonction \textit{boinc\_fraction\_done(double fraction\_done)} permet par exemple de communiquer le pourcentage de complétion de l'unité de travail au \textit{BOINC Manager}. Cette valeur est alors utilisée par ce dernier pour afficher une barre de progression à l'utilisateur (Fig.~\ref{boincmanager}). 
%TODO dire qu'on décrit pas tout et donner le lien + p e resolve_filename
% TODO exemple de job.xml

Parallèlement à cette utilisation "classique", il est également possible d'utiliser le \textsc{BOINC} \textit{wrapper}. Il s'agit d'un programme fourni avec le code source qui permet d'exécuter n'importe quelle application sur \textsc{BOINC}. Ce programme exécute les applications comme sous-processus et gère la communication avec le  \textsc{core client} \textsc{BOINC} (le code exécuté derrière l'interface graphique qu'est le \textit{BOINC Manager}).

Le(s) programme(s) appelé(s) par le \textit{wrapper} (ces programmes seront appelés des \textit{worker}) ainsi que les paramètres associés sont décrits dans un fichier XML. Il est par exemple possible de spécifier les noms des fichiers vers lesquels les flux \textit{stdin}/\textit{stdout}/\textit{stderr} doivent être redirigé. Il est également possible de spécifier le nom d'un fichier supposé contenir le pourcentage de progression de la tâche. Ce fichier est alors lu périodiquement par le \textit{wrapper} afin de communiquer l'état d'avancement au \textit{core client}. L'écriture de ce fichier est un responsabilité de l'application exécutée, c'est dans la seule modification devant être apportée au programme afin d'être exécuté sur \textsc{BOINC}. Il est cependant important de signaler que ceci est une option facultative. Si le mécanisme n'est pas implémenté par l'application, celle-ci peut tout à fait être exécutée sur \textsc{BOINC} mais le pourcentage de progression restera sur 0\% tout au long du calcul ce qui peut être très perturbant pour les utilisateurs. Ce mécanisme, bien que non nécessaire, est donc fortement recommandé.
% TODO ref

Dans le cadre de ce travail un objectif est de mettre à disposition des chercheurs un moyen d'exécuter des expériences. Il ne s'agit pas de mettre en place une expérience particulière, mais de permettre la mise en place, aussi facilement que possible, de n'importe quelle expérience. Tout naturellement c'est donc le \textit{wrapper} qui a été utilisé tout au long de ce travail.

% TODO autres langages etc ?

\section{Cadre applicatif: prédiction de propriétés structurelles de protéines}
\label{proteines}
\subsection{Introduction}
Le cadre applicatif choisi pour la réalisation de ce travail consiste en la prédiction de propriétés structurelles de protéines. Plus précisément, le travail a été réalisé dans le cadre des recherches de F. \textsc{Maes}, J. \textsc{Becker} et L. \textsc{Wehenkel} concernant la prédiction structurée multi-tâche itérative de propriétés structurelles de protéines~\cite{CAP}~\cite{POSTER}.

Cette section présente succinctement les enjeux et défis de la prédiction \textit{abinitio} de la structure tertiaire des protéines (section~\ref{abinitio}) ainsi que la solution proposée dans~\cite{CAP} (section~\ref{psmi}). 

\subsection{Prédiction de la structure tertiaire des protéines}
\label{abinitio}
La prédiction \textit{ab initio} de la structure tertiaire des protéines (i.e. le calcul de la position 3D de chaque atome à partir de la séquence d'acide aminés d'une protéine) constitue un des défis majeur de la bioinformatique à l'heure actuelle. Il s'agit d'un problème délicat et non résolu à ce jour. Les enjeux sont majeurs puisque la connaissance de la structure 3D d'une protéine permet aux biologistes de déduire énormément d'informations concernant le fonctionnement et le rôle de la protéines. Ces informations peuvent alors être utilisées pour comprendre certaines maladies afin de mieux les soigner. Les motivations dans ce domaine ne manquent donc pas.

Le problème de la prédiction \textit{ab initio} étant très difficile, l'approche actuellement suivie dans le cadre de l'apprentissage automatique consiste à diviser le problème en sous-problèmes plus simples: prédiction de la structure secondaire (hélices alpha, feuillets beta, ...), prédiction de l'accessibilité au solvant, prédiction de régions désordonnées, prédiction des matrices de contacts, ...

\subsection{Prédiction structurée multitâche itérative (\textsc{Psmi})}
\label{psmi}
L'approche classique consiste à résoudre de manière indépendante les divers sous-problèmes introduits à la section précédente. Les recherches de F. \textsc{Maes}, J. \textsc{Becker} et L. \textsc{Wehenkel}~\cite{CAP} proposent une solution alternative en proposant un cadre d'apprentissage générique pour la prédiction structurée multitâche. 

L'idée principale derrière ces recherches est simple: les divers sous-problèmes sont intimement liés entre eux et il parait donc intéressant de profiter des corrélations entre les différents problèmes afin d'augmenter la qualité des modèles appris. 

Dans le cadre générique développé dans~\cite{CAP}, une tâche est associée à chaque sous-problème. Le cadre repose sur l'assemblage d'un ensemble de modèles de prédiction structurée simple-tâche. L'algorithme proposé est un algorithme itératif fonctionnant par passes. A chaque passe un modèle est appris pour chaque tâche en se servant des données de base, mais également des prédictions actuelles pour chaque tâche.

Les expérimentations réalisées dans~\cite{CAP} sont plus qu'encourageantes puisque les résultats obtenus surpassent l'état de l'art en la matière.

\chapter{Installation et administration du serveur \textsc{BOINC}}
% TODO intro
\section{Premiers pas}
Après lecture de la documentation, la première étape fût l'installation du serveur \textsc{BOINC} sur mon ordinateur personnel. La démarche pour compiler le code du serveur et pour installer celui-ci est décrite en détails pour les plateformes de type \textit{Debian} sur le site de \textit{Berkeley}~\cite{BOINC}.

Les sources du serveur \textsc{BOINC} contiennent une application de test, \textit{uppercase}. Cette application permet de convertir le contenu d'un fichier texte en majuscules. Elle n'a donc aucun intérêt scientifique, mais permet de tester très rapidement que le serveur fonctionne comme attendu.

En plus de l'application proprement dite, les sources contiennent également un exemple de \textit{work generator}, de \textit{validator} et d'\textit{assimilator}. Tout est donc à disposition afin de tester l'infrastructure très rapidement. J'ai donc pu créer un projet de test "privé" (dont l'URL n'était pas publique) et j'ai pu ainsi me familiariser avec le fonctionnement du serveur.

\section{Installation à Montefiore}
Une fois ces premiers tests réalisés, j'ai décidé d'installer le serveur à Montefiore. Il a donc fallu trouver une machine et un local où l'installer. Après divers contacts avec le corps enseignant, j'ai obtenu une ancienne machine du réseau 8 et j'ai pu installer celle-ci dans le laboratoire RUN (\url{boinc.run.montefiore.ulg.ac.be}).

La machine en question est un Pentium 4 \@ $2,4$GHz avec 1Go de RAM. Cette "petite" configuration peut sembler surprenante pour un serveur, mais il faut bien se rendre compte que dans notre cas de figure, le serveur se contente de distribuer les unités et de récupérer les résultats. Contrairement à la situation classique, ici ce sont les clients qui calculent et non le serveur. Bien entendu, plus le nombre de clients augmente, plus la charge du serveur augmente mais durant les expérimentations réalisées, aucun problème du à la charge du serveur n'a été rencontré.

\section{Monitoring}
Comme expliqué dans la section précédente, la "petite" configuration du serveur peut faire peur de prime abord, c'est pourquoi j'ai rapidement décidé de mettre en place un système de monitoring du serveur. De manière générale c'est une bonne pratique de disposer d'outils pour monitorer un serveur. Cela permet en général de détecter la source d'un problème de performance (goulot d'étranglement au niveau réseau par exemple).

\subsection{Première approche: script CGI}
Le serveur \textsc{BOINC} est livré avec un script CGI permettant de visualiser sous forme graphique des fichiers textes dont le contenu est:
\begin{verbatim}
CIVDATE    UNIXDATE    VALUE1    VALUE2    ...
\end{verbatim}
où $CIVDATE$ est la date au format $\%Y:\%m:\%d:\%H:\%M$ et où $UNIXDATE$ est le \textit{timestamp} UNIX correspondant. Un exemple d'une ligne d'un tel fichier pourrait être:
\begin{verbatim}
2010:10:30:00:00    1288389602    24
\end{verbatim}

Pour pouvoir utiliser ce mécanisme, il faut donc avoir un moyen de générer ces fichiers textes de ce type contenant les valeurs intéressantes à monitorer. L'approche que j'ai utilisée consiste à utiliser des commandes de base UNIX dans des script \textit{shell} et à isoler l'information pertinente via les commandes de type \textit{grep}, \textit{awk}, \textit{tr}, \textit{sed}, ... Cette approche m'a permis d'obtenir des graphique pour: l'utilisation du disque dur, la charge CPU, la consommation réseau, la charge réseau, l'utilisation RAM et la puissance délivrée par le projet (\textit{floating point operations per second}, FLOPS).

Pour ce qui est de la puissance délivrée par le projet, quelques remarques s'imposent. Le script calculant cette valeur utilise la commande \textit{mysql} pour se connecter à la base de données du projet et sélectionne les résultats reçus au cours de la dernière minute\footnote{Le script est exécuté toutes les minutes.}. Pour chaque résultat, la base de données contient le temps CPU utilisé pour calculer le résultat ainsi qu'une estimation de la puissance du processeur utilisé (en FLOPS). Il est donc possible de calculer le nombre d'opérations qui ont été nécessaires pour chaque résultat. La somme de ces estimations divisé par l'intervalle de temps donne une estimation de la puissance délivrée par le projet.

L'ensemble des scripts est exécuté de manière périodique via la \textit{crontab} et l'exécution de ceux-ci remplit progressivement les fichiers \textit{logs} utilisés pour les graphiques. A titre illustratif, le script permettant de connaitre l'utilisation du disque dur se trouve dans le List.~\ref{shellhd}. %TODO les autres sont dans le répertoire ....


\lstset{language=bash,caption={\textit{shell} script: utilisation du disque dur},label=shellhd}
\begin{lstlisting}
#!/bin/bash

CIVDATE=`date "+%Y:%m:%d:%H:%M"`
UNIXDATE=`perl -e 'print time()'`
disk=`df -h | grep "/dev/sda1" | awk '{print $5}' | tr '%' ' '`

echo $CIVDATE $UNIXDATE $disk
\end{lstlisting}


\subsection{Deuxième approche: Munin}
Bien que la première approche fût fonctionnelle, celle-ci n'était pas assez "\textit{user-friendly}" à mon goût et l'écriture des script \textit{shell} n'était pas toujours facile. Je me suis donc tourné vers des solutions de monitoring gratuites ayant fait leur preuve. La solution \textit{Munin}~\cite{MUNIN} a retenu mon intérêt car elle est très facile d'utilisation, relativement \textit{plug-and-play}~\footnote{Il n'y a pas grand chose à configurer pour avoir accès aux graphiques de base.} et l'écriture de nouveaux \textit{plugins} est possible.

En utilisant le même principe que celui décrit à la section précédente, j'ai écrit un \textit{plugin} permettant de visualiser la puissance délivrée par le projet.

Deux exemples de graphique fournis par \textit{Munin} sont visibles Fig.~\ref{munin1} et Fig.~\ref{munin2}. L'ensemble des graphiques est accessible à l'adresse suivante: \url{http://boinc.run.montefiore.ulg.ac.be/munin/}.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.5]{img/munin1.png}
\caption{\textsc{Munin}: estimation du nombre de GFLOPS fourni par le projet}
\label{munin1}
\end{figure}

\begin{figure}[!h]
\centering
\includegraphics[scale=0.5]{img/munin2.png}
\caption{\textsc{BOINC}: activité MySQL}
\label{munin2}
\end{figure}


\section{Sauvegarde}
Dès le début du projet, il m'est apparu évident qu'il fallait mettre en place un système de sauvegarde du serveur.

\subsection{Première approche: machine virtuelle}
La première idée explorée fût l'installation du serveur dans une machine virtuelle\footnote{Le logiciel VMWare Server 2 a été utilisé~\cite{VMWARE}.}.
Cette solution présente certains avantages:
\begin{itemize}
\item La restauration d'une sauvegarde d'une machine virtuelle se fait très simplement et ne nécessite aucune re-configuration du serveur.
\item On peut très facilement changer de machine hôte (pour une plus puissante par exemple) puisqu'il suffit d'installer le logiciel de virtualisation et de lancer la machine virtuelle. Ceci représentait un atout majeur au début du projet car je n'étais pas encore persuadé que le serveur serait assez puissant.
%TODO autres avantages
\end{itemize}
Malheureusement cette solution a aussi ses inconvénients:
\begin{itemize}
\item Il faut arrêter la machine virtuelle pour pouvoir en faire une sauvegarde.
\item Le temps de sauvegarde est relativement important et la taille du fichier de sauvegarde également.
\item Bien que d'énormes progrès aient été fait en la matière, l'utilisation d'une machine virtuelle dégrade toujours un peu les performances.
\end{itemize}
Ce dernier inconvénient n'est pas réellement problématique ici, mais les deux autres constituent un problème majeur. En effet, il est important de faire des sauvegardes régulières (afin d'éviter la perte de résultats ou la perte de crédits (points) pour les volontaires~\footnote{La perte de crédits ne pose aucun problème d'un point de vue scientifique, mais une telle perte peut rendre les volontaires mécontents ou amener ceux-ci à penser que le projet n'est pas sérieux, ce qui serait nuisible au projet.}) et il est impensable d'arrêter le projet plusieurs heures chaque jour.

Enfin, pour que la sauvegarde soit fiable, celle-ci doit se trouver sur un autre disque dur ou mieux sur une autre machine. Il faudrait donc pouvoir transférer la sauvegarde par le réseau ce qui est relativement problématique vu sa taille importante. L'autre solution consistant à faire la sauvegarde sur un deuxième disque dur est également impossible car la machine utilisée ne comporte qu'un seul disque dur~\footnote{Pour la même raison, un système de sauvegarder de type RAID est également impossible.}. 

\subsection{Deuxième approche: sauvegarde réseau}
La deuxième approche consiste à ne sauvegarder que les parties nécessaires à la réinstallation du serveur en l'état de la sauvegarde. Il y a donc deux éléments à prendre en considération:
\begin{itemize}
\item La base de données.
\item Divers fichiers au sein du serveur (applications compilées, fichiers de configurations, répertoires upload/download du serveur, ...).
\end{itemize} 

L'implémentation de cette politique de sauvegarde a été réalisée à l'aide d'un script \textit{shell}. Celui-ci permet de faire les sauvegardes de manière automatique grâce à la \textit{crontab} et ces sauvegardes sont automatiquement transférées sur le réseau 8 (ms8xx). 

Le script s'articule en deux parties. La première partie consiste à effectuer un \textit{dump} des bases de données et à transférer celui-ci via la commande \textit{scp} sur le réseau 8. La deuxième partie consiste à sauvegarder l'ensemble des fichiers nécessaires à la restauration. Cette sauvegarde s'effectue directement en réseau et de manière incrémentale via la commande \textit{rsync}. Ainsi, seul les modifications sont transférées sur le réseau. % TODO code et/ou précisions
% TODO non du fichier

Lorsque l'on parle de sauvegarde automatique sur le réseau 8 se pose la question de l'authentification. Deux solutions différentes ont été apportées:
\begin{itemize}
\item \textit{expect}: Il s'agit d'un outil UNIX permettant d'automatiser l'exécution de programmes interactif. Ici, la partie interactive est la demande de mot de passe.
\item clé privée/publique: Les commandes \textit{scp} et \textit{rsync} utilisent un tunnel \textit{ssh}. Il est possible de réaliser l'authentification \textit{ssh} sans enter de mot de passe en utilisant le système de clé privée / clé publique. Il faut cependant que la privée ne soit pas protégée par une \textit{passphrase}! 
\end{itemize}
% TODO code ?

\subsection{Les fichiers \textit{log}}
Comme dans n'importe quel serveur, des fichiers \textit{log} sont générés en cours d'exécution. Ceux-ci sont d'un intérêt majeur lorsqu'il s'agit de comprendre un bug. La verbosité de ceux-ci peut-être contrôlée via les fichiers de configuration du serveur. 

Au fur et à mesure du temps, ces fichiers peuvent finalement occuper une place considérable. Il est donc important d'implémenter une politique de rotation de \textit{logs}. Pour ce faire, l'utilitaire \textit{logrotate} de Linux a été utilisé. L'exécution de \textit{logrotate} a lieu a chaque sauvegarde du serveur et la rotation a lieu selon les préférences définies dans le fichier de configuration. %TODO fichier config

\section{Communication avec les volontaires}
Le serveur \textsc{BOINC} est fourni avec un site internet basique. Celui-ci est principalement utilisé afin de communiquer avec les volontaires par l'intermédiaires de \textit{news} et d'un forum. Les sujets abordés vont des recherches effectuées par le projet jusqu'au résultat obtenus en passant par certains aspects plus techniques (disponibilités de WU, durée de celles-ci, consommation RAM, bugs, etc).

Comme mentionné dans la section~\ref{calculvolontaire}, la communication est un aspect à ne pas négliger pour un projet de calcul volontaire. Il est primordial d'intéresser les volontaires et de leur inspirer une certaine confiance. J'ai donc tout au long du projet essayé d'être aussi disponible que possible vis à vis des questions/remarques des volontaires et j'ai communiqué un maximum quant aux recherches effectuées et leurs résultats.
Toujours dans le but de rendre le projet attractif, j'ai également fait appel à L. \textsc{Schoonbrodt}, un ami graphiste, afin de réaliser un logo pour le projet et une feuille de style CSS. Le site internet du projet est accessible à l'adresse suivante: \url{http://boinc.run.montefiore.ulg.ac.be/evo/}

\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{img/evo.png}
\caption{Logo du projet \textsc{BOINC} mis en place (\textsc{Evo@home})}
\label{evologo}
\end{figure}

J'ai également fait le nécessaire pour que le projet soit référencé sur les différents sites de statistiques (crédits) de \textsc{BOINC}.

Ce travail de communication, bien que ne présentant qu'un intérêt pédagogique limité, était cependant nécessaire pour faire de ce projet un succès.
% TODO dire que c'est evo@home
% TODO images des stats
%\section{Sécurité}
% TODO

\section{Inconvénients liés à l'utilisation de \textsc{BOINC}}
\subsection{Introduction}
Bien que l'utilisation de \textsc{BOINC} présente de nombreux avantages (voir section~\ref{avantagesboinc}), l'utilisation pratique de cette plate-forme tout au long du projet a permis de mettre en avant quelques inconvénients qu'il est important de signaler.

\subsection{Contrainte liée à la consommation RAM}
Lorsqu'une machine dédiée est utilisée pour réaliser des tâches de calcul intensif (telle que la machine \textit{Monster24} comportant 24 coeurs et des dizaines de giga de RAM), la consommation mémoire n'est pas nécessairement un paramètre critique et il est en général plus tentant de privilégier le temps d'exécution par rapport à la consommation mémoire. 

Dans le cadre de \textsc{BOINC} c'est la règle contraire qu'il faut privilégier. En effet, le code est destiné à être exécuté sur les machines de particuliers et ces machines sont équipées avec beaucoup moins de RAM (quelques giga maximum) que des machines dédiées. L'exécution de \textsc{BOINC} est sensée être complètement transparente pour l'utilisateur: \textsc{BOINC} est sensé utiliser les ressources inutilisées des ordinateurs et non pas monopoliser l'ensemble des ressources. Ceci est d'autant plus vrai concernant l'utilisation RAM puisque un ordinateur obligé de \textit{swappé} faute de RAM ne peut se comporter de manière normale (temps de latence très important).

Les retours des utilisateurs ainsi que mon expérience personnelle dans le domaine ont conduit à fixe arbitrairement une limite à ne pas dépasser: 1Go. Cette limite est d'ailleurs en accord avec les statistiques de consommation RAM de projets \textsc{BOINC}~\cite{WUPROP}. Il est important que les applications développées respectent cette limite afin d'éviter de décourager les volontaires. 

Concrètement, les premières expériences réalisées sur \textsc{BOINC} dans le cadre de ce projet n'utilisaient pas plus de 500Mo de RAM. Alors que le projet venait tout juste d'être rendu public, ces expériences ont permis d'atteindre très rapidement une puissance de plus de 1TFLOPS. Les expériences réalisées ultérieurement ont en revanche requis 1,5Go de RAM en moyenne. L'effet sur la puissance délivrée par le projet a été immédiate puisque celle-ci est tombée à 100GFLOPS de moyenne. Deux causes expliquent cette forte baisse:
\begin{itemize}
\item La consommation de 1,5Go de RAM est trop génante pour certains utilisateurs.
\item Normalement, les ordinateurs multi-cores peuvent exécuter plusieurs \textit{work units} \textsc{BOINC} simultanément. Cependant, compte tenu de la consommation de 1,5Go de RAM, le projet a du être configuré afin de limiter le nombre de \textit{work units} en cours d'exécution à 1. Ce réglage permet d'éviter de \textit{freezer} les ordinateurs multi-cores ne disposant pas d'au moins 1,5Go RAM par core. En revanche, cela implique que le projet ne peut tirer parti des ordinateurs multi-core.
\end{itemize}

Les applications trop gourmandes en RAM ne sont donc pas adaptées au calcul distribué volontaire.

\subsection{Difficultés dues à la diversité des machines}
Une difficulté inhérente au modèle \textsc{BOINC} est la diversité des machines sur lesquels l'application est susceptible d'être exécutée. Il faut pouvoir fournir des exécutables qui se comportent correctement sur un maximum de machine (afin de maximiser la puissance délivrée par le projet) et cela n'est pas toujours facile.

A côté des contraintes présentées ci-dessous, la diversité des machines clients peut également être vue comme un avantage. En effet, dans le cadre d'une utilisation pratique, cette diversité a souvent conduit à détecter des \textit{bugs} qui ne se manifestaient pas sur les machines utilisées pour le développement.

\subsubsection{Code multi-platefome}
La première restriction est d'écrire du code multi-plateforme. Il faut éviter au maximum les recours aux fonctions spécifiques à un OS particulier et le cas échéant prévoir les alternatives pour les OS principaux (Windows, Linux, OS X). Dans le cadre de ce projet, la librairie \textit{Juce}~\cite{JUCE} a été utilisée. Celle-ci est multi-plateforme et fournit par exemple toutes les fonctions nécessaires pour manipuler des fichiers, créer des \textit{threads},  synchroniser ceux-ci, ... ce qui facilite le travail d'implémentation multi-plateforme. 

\subsubsection{Minimiser les dépendances}
Lorsque que l'on compile une application destinée à être exécutée sur d'autres machines, il est primordial de minimiser les dépendances. Ceci est particulièrement vrai en ce qui concerne les librairies dynamiques.

Comme mentionné précédemment, les applications clients qui ont été utilisées dans le cadre de ce projet (développées par F. \textsc{Maes} et J. \textsc{Becker}) reposent sur la librairie \textit{Juce}. Or cette librairie contient entre autres des composants graphiques et des composants audio qui ne sont d'aucune utilité dans le cadre d'applications clients exécutées chez des utilisateurs \textsc{BOINC}. Les premières versions compilées dépendaient donc de librairies graphiques externe comme X11 par exemple. Bien que ce genre de librairies soient souvent installées, ce n'est pas toujours le cas et dans le cadre de \textsc{BOINC} un certain nombre d'ordinateurs clients sont en réalité des serveurs dépourvu d'interface graphique et donc de X11.

Fort heureusement, la librairie \textit{Juce} étant bien conçue, il est possible de compiler celle-ci en excluant certaines parties inutiles (par exemple tout ce qui touche à l'interface graphique, à l'audio, au réseau, ...). Cependant, bien que l'applications clients ne dépendent pas de ces composants, ceci n'est pas vrai pour la totalité de la librairie développée par F. \textsc{Maes}. Il fallait donc un moyen simple d'activer/désactiver ces composants. 

L'environnement de développement utilisé dans le cadre de ce projet utilise l'outil de compilation \textit{CMake}~\cite{CMAKE}. Cet outil est relativement puissant et permet de définir facilement des options de compilation. Il a été ainsi possible de définir des options permettant d'exclure/inclure facilement les composant réseau/UI lors de la compilation\footnote{F. \textsc{Maes} a également participé à cette tâche pour des parties plus pointues de sa librairie telle que l'introspection.}.  

\subsubsection{Compatibilité}
Si aucune précaution n'est prise, un logiciel compilé sur une version récente de linux ou de OS X ne fonctionnera pas nécessairement sur des versions plus anciennes. Ces problèmes ont été rencontrés par des utilisateurs et ont été reportés sur le forum du projet.

En ce qui concerne OS X, il est possible de spécifier à la compilation la version minimum de l'OS sur lequel le programme doit pouvoir être exécuté. Pour ce faire il faut spécifier une valeur pour la variable \textit{DEPLOYMENT\_TARGET}. Bizarrement, il semble que cela ne soit pas suffisant. La lecture de divers messages sur internet~\cite{APPLE_MAIL} a finalement conduit à utiliser la configuration présentée dans le Tab.~\ref{configosx}. Cette configuration semble résoudre tous les problèmes de compatibilités sous OS X.
\begin{table}[htdp]
\caption{Configuration pour la compilation sous OS X}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Variable \textbackslash Architecture & i386 & x86\_64\\
\hline
DEPLOYMENT\_TARGET & 10.4 & 10.5\\
SYSROOT & MacOSX10.4u.sdk & MacOSX10.5.sdk\\
VERSION\_MAX\_ALLOWED & 1040 & 1050\\
VERSION\_MIN\_REQUIRED & 1040 & 1050\\
GCC version & 4.0 & 4.0\\
\hline
\end{tabular}
\end{center}
\label{configosx}
\end{table}%

Pour ce qui est de la plateforme Linux, deux machines virtuelles aussi vieilles que possible (32 bits et 64 bits) mais permettant de compiler le code ont été utilisées. La configuration utilisée est une distribution Dapper de Ubuntu (6.06, kernel 2.6.15) sur laquelle GCC 4.0.3 est installé. Cette configuration semble avoir évité la plupart des problèmes de compatibilité.



\chapter{Algorithmes évolutionnaires développés et résultats}
\section{Introduction}
Cette section s'intéresse aux recherches faites durant ce travail concernant les algorithmes évolutionnaires et plus précisément les algorithmes à estimation de distribution (EDA).

Les sections~\ref{evointro} et~\ref{edaintro} présentent les algrithmes évolutionnaires et les algorithmes à estimation de distribution d'une manière générale.

Dans la section~\ref{edaasynch} un EDA original mieux adapté au contexte du calcul distribué est présenté. La section~\ref{mixture} présente également une contribution originale concernant la construction de la distribution utilisée par l'EDA.

La section~\ref{edaimprove} soulève quelques problèmes pratiques rencontrés en général avec les EDA et propose quelques solutions trouvées dans la littérature.

Enfin, la section~\ref{results} présente les résultats obtenus avec ce nouvel EDA.

\section{Algorithmes évolutionnaires}
\label{evointro}
Les algorithmes évolutionnaires représentent une classe d'algorithmes d'apprentissages s'inspirant de la théorie de l'évolution de \textit{Darwin}. L'idée de base est de faire évoluer un ensemble de solutions à un problème donné vers de meilleurs solutions. Ce type d'algorithme est en général utilisé pour l'optimisation.

Afin de bien comprendre l'idée qui se cache derrière ce type d'algorithmes, il est indispensable de faire le parallèle avec la théorie de l'évolution. Pour rappel cette théorique indique que l'évolution des êtres vivants tend à produire des individus plus adaptés à leur environnement. Différents mécanismes entrent en jeux dans ce processus~\cite{WIKI_EVO}:
\begin{itemize}
\item Les propriétés d'un individu sont codées dans ses gènes.
\item Une population est composée d'individus différents.
\item Selon ses caractéristiques, un individu est plus ou moins bien adapté à son environnement.
\item Les individus transmettent une partie de leurs gènes à leur descendance.
\item Les individus plus adaptés se reproduisent plus efficacement.
\end{itemize}

Dans le cadre de l'optimisation, on cherche en général à fixer la valeur d'un certain nombre de paramètres afin de maximiser (ou minimiser) une fonction objectif (\textit{fitness}). Dans ce contexte, un jeu de paramètres (i.e. une valeur associée à chaque paramètre, une solution potentielle du problème d'optimisation) représente un individu. Les caractéristiques de la solution (de l'individu) sont les valeurs associées à chaque paramètre, ceci représente en quelque sorte le génotype. En biologie, l'expression du génotype est le phénotype. Ici les caractéristiques de la solution s'expriment au travers de la fonction objectif. De manière générale, les algorithmes évolutionnaires sont conçus de manière à favoriser la transmission des génotypes conduisant à un bon score.  

L'Algorithm~\ref{evoalgo} et la Fig.~\ref{evoschema} décrivent le fonctionnement général de cette classe d'algorithmes.

\begin{algorithm}                      
\caption{Algorithme évolutionnaire général~\cite{WIKI_EVO}}          
\label{evoalgo}                           
\begin{algorithmic}                    
\STATE $X = i()$ \COMMENT{Génération de la population initiale}
\STATE $scores = \textnormal{f}(X)$ \COMMENT{Evaluation de la population initiale (\textit{fitness})}
\WHILE{Critère d'arrêt non atteint}
\STATE $X' = \textnormal{Se}(X, scores)$ \COMMENT{Sélection d'une partie de la population sur base des scores}
\STATE $newX = \textnormal{Cr}(X')$ \COMMENT{Croisement/reproduction des individus sélectionnés} 
\STATE $newX = \textnormal{Mu}(newX)$ \COMMENT{Mutation de la descendance}
\STATE $scores = \textnormal{f}(newX)$ \COMMENT{Evaluation de la nouvelle population (\textit{fitness})}
\STATE $X = newX$ \COMMENT{Remplacement de la population initiale par la nouvelle population}
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\begin{figure}[!h]
\centering
\includegraphics[scale=0.35]{img/evoschema.jpg}	
\caption{Algorithme évolutionnaire général~\cite{WIKI_EVO}}
\label{evoschema}
\end{figure}

Ces algorithmes, bien qu'assez simple conceptuellement, produisent d'excellent résultats dans beaucoup de domaine.

\section{Algorithmes à estimation de distribution}
\label{edaintro}
\subsection{Introduction et algorithme général}
\label{edageneral}
Les algorithmes à estimation de distribution (\textit{Estimation of distribution algorithm}, EDA) sont des variations plus "évoluées" des algorithmes évolutionnaires classiques. Contrairement à ces-derniers, les EDA n'utilisent pas d'opérateurs de croisement ou de mutation. En effet, un EDA cherche à estimer les relations entre les différentes variables d'un problème d'optimisation en y associant une distribution de probabilité. Les nouveaux individus (enfants) sont alors générés directement à partir de la distribution de probabilité.

L'algorithme général d'un EDA est présenté dans l'Algorithm~\ref{edaalgo}. La Fig.~\ref{edaschema} présente quant à elle l'évolution de la distribution et de la population au cours des itérations. Dans l'exemple présenté la fonction de \textit{fitness} présente un seul optimum en $O$ et une loi normale est utilisée pour l'estimation de la distribution (univariée).

\begin{algorithm}                      
\caption{EDA général}          
\label{edaalgo}                           
\begin{algorithmic}                    
\STATE $P = \textnormal{sample}(PDu_{init})$ \COMMENT{Tirage aléatoire d'un ensemble d'individus selon une distribution de probabilité donnée (population initiale)}
\STATE $scores = \textnormal{f}(P)$ \COMMENT{Evaluation de la population initiale (\textit{fitness})}
\WHILE{Critère d'arrêt non atteint}
\STATE $PS = \textnormal{Se}(X, scores)$ \COMMENT{Sélection d'une partie de la population sur base des scores}
\STATE $PDe = \textnormal{buildDistribution}(PS)$ \COMMENT{Construction d'une nouvelle distribution sur base des individus sélectionnés}
\STATE $PDu = PDe$
\STATE $P = \textnormal{sample}(PDu)$ \COMMENT{Tirage aléatoire d'un ensemble d'individus selon la nouvelle distribution}
\STATE $scores = \textnormal{f}(P)$ \COMMENT{Evaluation de la nouvelle population (\textit{fitness})}
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\begin{figure}[!h]
\centering
\includegraphics[scale=0.35]{img/edaschema.jpg}
\caption{EDA général: évolution de la distribution et de la population~\cite{WIKI_EDA}}
\label{edaschema}
\end{figure}


\subsection{Les EDA, une famille d'algorithmes}
L'algorithme présenté dans Alg.~\ref{edaalgo} est le cannevas général d'un EDA. Cet algorithme laisse de nombreux degrés de liberté engendrant autant d'algorithmes différents.

Un des choix influençant le plus le comportement de l'algorithme est le choix du modèle de distribution à utiliser pour décrire l'état de la population:
\begin{itemize}
\item modèle sans dépendance
\item modèle avec dépendances bi-variantes 
\item modèle avec dépendances multi-variantes
\end{itemize}

Dans les algorithmes utilisant un modèle sans dépendance, le modèle est un ensemble de distributions définies sur une seule variable. Autrement dit, le modèle est factorisé de la sorte:
$$ P(X) = \prod_{i=1}^{n} P(x_i)$$
Cette famille d'algorithmes regroupe entre autres: \textit{P}opulation-{B}ased {I}ncremental {L}earning (PBIL)~\cite{PBIL}, \textit{Univariate Marginal Distribution Algorithm} (UMDA)~\cite{CLEVER_ALGO} et \textit{Compact Genetic Algorithm} (cGA)~\cite{CGA}. %TODO modèle math

Les algorithmes reposant sur un modèle avec des dépendances bi-variantes reposent en général sur la construction d'un graphe de dépendances sur chaque population afin d'isoler les dépendances. Ce type d'algorithmes comprend notamment: \textit{Bivariate Marginal Distribution Algorithm} (BMDA)~\cite{BMDA}, \textit{Optimal Dependency Trees Combining Multiple Optimization Runs with Optimal Dependency Trees} (COMIT)~\cite{COMIT}.
% TODO modèle math

En ce qui concerne les modèles avec dépendances multi-variantes, la plupart des algorithmes sont basé sur la construction d'un réseau bayésien. Un des premiers algorithmes utilisant cette technique est le \textit{Bayesian Optimization Algorithm} (BOA)~\cite{BOA}. La majorité des algorithmes utilisant un modèle avec dépendances multi-variantes sont basés sur le BOA.

Différentes variantes existent également selon l'opérateur de sélection et l'opération exacte utilisée pour la génération de la nouvelle population.
% TODO lire tt les articles et détailler + si nécessaire
% TODO vérifier que j'ai pas oublier des cite

\section{EDA Asynchrone}
\label{edaasynch}
\subsection{Introduction}
Quelle que soit l'EDA utilisé, il s'agit d'un processus itératif. Dans l'algorithme général décrit dans la section~\ref{edageneral} une population de taille fixe est générée à chaque itération et ce dès que chaque individu de la population précédente a été évalué. Cette approche classique n'est pas applicable en pratique au cas de \textsc{BOINC} (et plus généralement au calcul distribué) à cause des temps de latence. En effet, ce système de génération des individus par \textit{batch} rendrait l'algorithme très inefficace en pratique.

Pour comprendre le phénomène il est utile de considérer un scénario simplifié. Dans ce scénario la taille de la population est fixée à 100 et 100 volontaires participent au projet:
\begin{enumerate}[1)]
\item Génération de 100 individus.
\item Chaque volontaire récupère 1 individu à évaluer.
\item Après 10 minutes, tous les volontaires ont renvoyé leur résultat, sauf un.
\item Il n'y a plus de travail disponible (plus d'individus à évaluer) sur le serveur \textsc{BOINC} et les 99 volontaires ne peuvent donc pas calculer pour le projet. Il sont contraint d'attendre le résultat du dernier volontaire.
\item Après 4 heures, le dernier volontaire renvoie son résultat.
\item Une nouvelle population de 100 individus est générée.
\item Les volontaires peuvent à nouveau calculer.
\end{enumerate}
Il s'agit bien entendu d'un scénario très simplifié, mais l'idée est là: si un EDA classique est utilisé, énormément de temps sera perdu à "attendre" dans le processus d'optimisation. 

Pour réduire ce temps d'attente, il est possible de spécifier dans la configuration du serveur \textsc{BOINC} le temps maximal après lequel une unité doit avoir été renvoyée, mais cela n'est pas suffisant. Cette section vise à présenter l'algorithme original développé afin de contourner ce problème.

\subsection{L'algorithme}
Comme mentionné dans la section précédente, le but de cette variation de l'EDA classique est d'empêcher la situation où des volontaires se trouvent dans l'obligation d'attendre car il n'y a plus d'individus prêt à être évalué. Formulé ainsi, la solution est évidente: il faut essayer de maintenir un nombre minimum d'individus en cours d'évaluation. Ce nombre est simplement la différence entre le nombre total d'individus créés et le nombre total d'individus déjà évalués. 

Afin que l'algorithme présenté ait du sens il faut bien entendu que la fonction d'évaluation ($f$, \textit{fitness}) soit asynchrone. Dans le cas de \textsc{BOINC} l'évaluation peut-être décomposée en 3 étapes:
\begin{enumerate}[1)]
\item Envoi par l'optimiseur d'un individu sur le réseau \textsc{BOINC} pour évaluation.
\item Evaluation de l'individu par un volontaire \textit{via} la fonction de \textit{fitness}.
\item Récupération du résultat par l'optimiseur.
\end{enumerate}

L'algorithme général de l'EDA asynchrone proposé est présenté dans l'Algorithm~\ref{asyncedaalgo}. Les résultats sont récupérés par un \textit{thread} auxiliaire qui n'est pas décrit ici. 

% TODO dire qu'en pratique on maintient un certain nombre en fct du nb de volontaires

% TODO détailler plus
\begin{algorithm}                      
\caption{EDA Asynchrone: algorithme général}          
\label{asyncedaalgo}                           
\begin{algorithmic}   
\WHILE{Critère d'arrêt non atteint}
\IF{nombre d'individus en cours d'évaluation trop faible}
\STATE $X = \textnormal{sample}(PD)$
\STATE send$(X)$
\ENDIF
\IF{assez de résultats disponibles}
\STATE $PD = \textnormal{buildDistribution}()$
\ENDIF
\ENDWHILE
             
\end{algorithmic}
\end{algorithm}

\section{Utilisation d'une mixture pour la distribution}
\label{mixture}
Une contribution de ce travail est l'utilisation de mixtures pour représenter la distribution de l'EDA. Cette technique répond à un problème pratique courant: lorsque la taille de la population sélectionnée est très petite~\footnote{Soit car la population est elle même de petite taille, soit parce que le critère de sélection doit être fort pour assurer la convergence.}, l'EDA a tendance à diverger car il converge (se spécialise) trop rapidement. 

Afin d'éviter ce genre de problèmes, les EDA implémentés construisent leur distribution comme une mixture de distributions. Plus précisément, à chaque itération la distribution construite est une mixture de l'ancienne distribution et de la distribution apprise à l'aide des meilleurs individus de cette itération. Le paramètre $slowingFactor$ permet de contrôler la probabilité des deux distributions au sein de la mixture, i.e. lors de l'échantillonnage l'ancienne distribution est choisie avec une probabilité de $slowingFactor$ tandis que la nouvelle distribution est choisie avec une probabilité de $1-slowingFactor$. Bien entendu, une valeur nulle pour le paramètre $slowingFactor$ permet de désactiver ce mécanisme.

\section{Amélioration de la convergence des EDA}
\label{edaimprove}
Un problème courant avec les EDA est la convergence trop rapide vers un optimum local empêchant ainsi la convergence vers l'optimum global. La source de ce problème vient du manque de diversité dans la population générée lorsque l'EDA approche un optimum. 

Le cas d'un EDA utilisant des distributions gaussiennes peut-être considéré afin de mieux comprendre le phénomène. Pour plus de facilité, le cas d'une fonction à une dimension est considéré. Si le couple $(\mu, \sigma)$ initial ne permet pas (i.e. avec une probabilité suffisante) d'atteindre l'optimum global mais permet d'atteindre un optimum local (proche de $\mu$ initial), alors la distribution apprise à l'itération suivante se rapprochera de cet optimum local et $\sigma$ diminuera. Se rapprocher de l'optimum local n'est pas un problème en soit, mais c'est la diminution de $\sigma$, i.e. la baisse de diversité, qui est problématique puisque celle-ci ne permettra pas d'atteindre l'optimum global si elle diminue trop fortement.

Ce problème est bien entendu également valable pour les fonctions $fitness$ à plusieurs dimensions. Il s'agit d'un problème typique avec les algorithmes de type EDA. L'article~\cite{DIVERSITE} décrit plus en détails la nature du problème et propose quelques solutions. Celles-ci consistent principalement à utiliser des heuristiques afin de ne mettre à jour $\sigma$ que lorsque l'état de l'optimiseur semble proche de l'optimum global. L'heuristique employée consiste par exemple à regarder la distance entre le vecteur moyen des caractéristiques de la population et le vecteur des caractéristiques de l'individu ayant obtenu le meilleur score: une distance faible suggère que l'optimiseur est proche de l'optimum global tandis qu'une distance élevée suggère que l'état de l'optimiseur tend à se déplacer vers une autre région et dans ce cas la variance ne doit pas être réduite. Ces techniques n'ont pas été implémentées dans ce travail, mais il s'agit de perspectives d'amélioration intéressantes.

\section{Expériences réalisées et résultats}
\label{results}
\subsection{Introduction}
Cette section vise à présenter plus concrètement les deux EDA implémentés (classique et asynchrone) ainsi que les expériences réalisées à l'aide de ces EDA et les résultats obtenus. % TODO finir intro

La section s'articule en quatre volets:
% TODO ref
\begin{itemize}
\item Présentation concrète des EDA utilisés.
\item Présentations des fonctions de tests utilisées.
\item Comparaison de la version classique et de la version asynchrone sur plusieurs fonctions de test typiques.
%\item Comportement de l'EDA sur différentes fonctions de test typiques. %TODO ?
\item Résultats obtenus sur un problème concret en utilisant l'EDA Asynchrone et l'infrastructure BOINC.
\end{itemize}

\subsection{Implémentation concrète des EDA}
Les EDA implémentés utilisent un modèle sans dépendance. Les variables de la fonction $fitness$ sont donc considérées comme étant indépendantes. Ce type d'EDA bien qu'assez simple conceptuellement donne souvent de bons résultats sur des problèmes pratiques. De plus, étant donné qu'aucune structure d'arbre ou de réseau Bayésien n'est impliquée dans la construction des distributions, ce type d'algorithmes est très efficace et permet de gérer des populations de grande taille.

L'implémentation réalisée permet d'associer n'importe quel type de distribution à chaque variable, la seule contrainte étant que la distribution puisse être apprise sur base d'un \textit{dataset}~\footnote{Le détail de l'implémentation est présenté dans le chapitre~\ref{genie}.}. En pratique ce sont principalement des distributions normales (pour les réels) ou de \textsc{Bernoulli} (pour les types énumérés) qui ont été utilisées. Pour les variables entières, une version discrétisée de la loi normale à été utilisée avec possibilité de fixer un domaine de définition~\footnote{Concrètement les échantillons d'une loi normale sont arrondis et ramenés dans le domaine de définition.}.

Les paramètres des EDAs sont les suivants:
\begin{itemize}
\item $populationSize$: taille de la population, celle-ci est fixe.
\item $numBests$: nombre d'individus à sélectionner pour la mise à jour de la distribution, ce nombre est fixe également.
\item $numIterations$: le critère d'arrêt est un nombre fixé d'itérations
\end{itemize}    
Pour la version asynchrone un paramètre supplémentaire permet de fixer le nombre d'évaluations en cours qu'il faut maintenir $numEvaluationsInProgress$.

\subsection{Banc de test}
Afin de permettre de tester facilement la qualité des EDA implémentés, un banc de test a été développé. Celui-ci reprend les 14 premières fonctions du \textit{benchmark} proposé dans~\cite{TESTBED}. Il s'agit de fonctions à paramètres réels dont la dimension peut être fixée par l'utilisateur. La valeur des fonctions à l'optimum est également déterminée par l'utilisateur. Les 14 fonctions implémentées couvrent 3 types de fonction:
\begin{itemize}
\item Fonctions séparables.
\item Fonctions faiblement ou moyennement conditionnées.
\item Fonctions avec un nombre de contionnement élevé et unimodales. % TODO verif définition unimodale
\end{itemize}

\subsection{EDA classique \textit{vs.} EDA Asynchrone}
\label{edavsasync}
La version asynchrone de l'EDA proposée dans ce travail permet de résoudre le problème de performance dû aux temps de latence induits par l'utilisation du calcul distribué (section~\ref{edaasynch}). Cependant, il est utile de s'interroger sur l'impact qu'a cette modification de l'EDA sur la convergence de l'algorithme.

Intuitivement, plus $numEvaluationsInProgress$ est petit, plus le comportement de la version asynchrone doit s'approcher du comportement de la version synchrone puisqu'une valeur de $numEvaluationsInProgress$ égale à 1 engendre un comportement identique à la version synchrone.

Pour comprendre l'effet d'un $numEvaluationsInProgress$ différent de 1, il faut se poser la question de l'impact que cela a sur l'EDA. Dans le "pire" des cas, la distribution est mise à jour alors qu'il y a déjà $numEvaluationsInProgress$ individus générés et qui sont en cours d'évaluations. Ces individus, générés avant la mise à jour de la distribution, n'auraient pas été générés avec la version classique de l'EDA et ceux-ci ne sont - normalement - pas susceptibles d'améliorer la distribution de l'itération suivante puisqu'ils ont été générés à partir de l'ancienne distribution. En d'autres termes, ces individus viennent "polluer" la population suivante et retarde ainsi légèrement le processus de convergence.

Afin de vérifier ces intuitions théoriques, des tests ont été réalisés sur quelques fonctions de \textit{benchmark}. Pour chaque test les paramètres suivant ont été utilisés:
\begin{itemize}
\item $f(\bf{x}^*) = 0$
\item $\bf{x} \in $ \cal{R}$^{5}$
\item $populationSize = 100$
\item $numBests = 30$
\item $numIterations = 40$
\end{itemize}
L'évaluation des fonctions de test étant quasi instantanée, il était impensable de réaliser ces expériences dans un environnement distribué. Afin de simuler le comportement de celui-ci, le temps requis pour l'évaluation des fonctions a été altéré de manière aléatoire grâce à l'ajout de sleep\textit{((\textnormal{rand}() \% 10) + 5)} et les évaluations ont été réalisées dans un environnement \textit{multi-threads}. 

Les résultats sont visibles Fig.~\ref{compare_eda_async_f10_1},~\ref{compare_eda_async_f10_2}, Fig.~\ref{compare_eda_async_f13_1},~\ref{compare_eda_async_f13_2} et Fig.~\ref{compare_eda_async_f14_1},~\ref{compare_eda_async_f14_2}. Ces courbes représentent l'évolution du meilleur score de l'itération en fonction de l'itération. Ceux-ci confirment les constations théoriques faites précédemment. Il est intéressant de remarquer que lorsque $numEvaluationsInProgress < populationSize$ la déterioration de la convergence est très légère.

\begin{figure}[!h]
\centering
\subfigure[Processus complet]{
\includegraphics[scale=0.4]{./data/compare_eda_async_f10.pdf}
\label{compare_eda_async_f10_1}
}
\subfigure[Dernière itérations]{
\includegraphics[scale=0.4]{./data/compare_eda_async_f10_zoomed.pdf}
\label{compare_eda_async_f10_2}
}
\label{compare_eda_async_f10}
\caption{Comparaison EDA \textit{vs.} AsyncEDA: Ellipsoidal Function (mal-conditionnée)}
\end{figure}

\begin{figure}[!h]
\centering
\subfigure[Processus complet]{
\includegraphics[scale=0.4]{./data/compare_eda_async_f13.pdf}
\label{compare_eda_async_f13_1}
}
\subfigure[Dernière itérations]{
\includegraphics[scale=0.4]{./data/compare_eda_async_f13_zoomed.pdf}
\label{compare_eda_async_f13_2}
}
\label{compare_eda_async_f13}
\caption{Comparaison EDA \textit{vs.} AsyncEDA: Sharp Ridge Function}
\end{figure}

\begin{figure}[!h]
\centering
\subfigure[Processus complet]{
\includegraphics[scale=0.4]{./data/compare_eda_async_f14.pdf}
\label{compare_eda_async_f14_1}
}
\subfigure[Dernière itérations]{
\includegraphics[scale=0.4]{./data/compare_eda_async_f14_zoomed.pdf}
\label{compare_eda_async_f14_2}
}
\label{compare_eda_async_f14}
\caption{Comparaison EDA \textit{vs.} AsyncEDA: Different Powers Function}
\end{figure}

\subsection{Utilisation de l'EDA Asynchrone sur \textsc{BOINC} pour résoudre un problème pratique}
L'expérience réalisée est directement en rapport avec les recherches de F. \textsc{Maes}, J. \textsc{Becker} et L. \textsc{Wehenkel} concernant la prédiction structurée multitâche itérative de propriétés structurelles de protéines~\cite{CAP} (voir section~\ref{psmi}).

Les expérimentations réalisées dans~\cite{CAP} se basent notamment sur le \textit{dataset} \textit{Protein Data Bank} (PDB)~\cite{PDB}. Cependant, cette données ne sont pas utilisées telles quelles. Une série des pré-traitements sont appliqués afin d'enrichir les données. L'opération consiste en quelque sorte à établir un "profil génétique" de chaque séquence d'acides aminés. Il s'agit là d'une opération de type extraction de \textit{features}. La qualité des \textit{features} extraites influence directement la qualité du modèle appris.

L'opération d'extraction de \textit{features} est contrôlée par un ensemble de paramètres. L'expérience réalisée décrite dans cette section a utilisé l'EDA Asynchrone sur le réseau \textsc{BOINC} afin d'améliorer la qualité du modèle appris. 
 
F. \textsc{Maes} ayant déjà réalisé des expérimentations dans ce domaine, un jeu de paramètres relativement bons était déjà disponible. L'objectif était donc de trouver un jeu de paramètre permettant d'améliorer encore les résultats grâce à l'EDA. La distribution initiale de l'EDA a donc été choisie afin d'être plus ou moins centrée sur cette meilleur solution mais de grands écarts types ont été utilisé afin de permettre de découvrir d'autres solutions optimales. Cette expérience ayant été réalisée sur le réseau \textsc{BOINC} c'est bien entendu la version asynchrone de l'EDA qui a été utilisée. Cependant, cette expérience ayant été réalisée avant les expériences menées dans la section.~\ref{edavsasync}, les remarques faites quant à la valeur de $numEvaluationsInProgress$ n'ont pas été prises en compte.

Pour cette expérience, les paramètres utilisés ont été les suivants:
\begin{itemize}
\item $populationSize = 500$
\item $numBests = 150$
\item $numEvaluationsInProgress = 750$
\item $slowingFactor = 0.15$
\end{itemize}

La Fig.~\ref{asynceda1} présente l'évolution du meilleur score de chaque itération en fonction de l'itération. Comme espéré, cette courbe est principalement décroissante, ce qui tend à prouver que l'EDA Asynchrone fonctionne comme attendu. Il est particulièrement intéressant de remarquer que cette courbe est décroissante malgré le fait que la distribution initiale de l'EDA était centrée sur l'ancien meilleur score. 

La Fig.~\ref{scoresMean} présente quant à elle l'évolution du score moyen obtenu à chaque itération. Encore une fois, la courbe est décroissante ce qui est bien le résultat attendu. Il est intéressant de remarquer que la décroissante est plus faible dans les dernières itérations ce qui tend à montrer que l'optimiseur a convergé et qu'il ne permettra normalement plus d'améliorer significativement le score.

Pour cette expériences, 3 \textit{datasets} ont été utlisé:
\begin{itemize}
\item $train$ : il s'agit des données utilisées par le \textit{learner} pour l'apprentissage. 
\item $validation$ : il s'agit des données utilisées à la fin de la phase d'apprentissage afin de calculer le score obtenu. Ces données sont bien entendu différentes de celles contenues dans $train$ afin d'éviter le sur-apprentissage. C'est le score fourni par l'évaluation sur ce \textit{dataset} que l'optimiseur cherche à minimiser.
\item $test$ : ce dernier \textit{dataset} (également indépendant des deux autres) permet de vérifier que l'optimiseur ne fait pas de sur-apprentissage.
\end{itemize}
Le Tab.\ref{tabimprove} reprend les scores de validation et de test avant et après optimisation grâce à l'EDA Asynchrone sur \textsc{BOINC}. Le meilleur score a pu être amélioré de 1\% ce qui constitue un résultat remarquable compte tenu du fait que l'ancien meilleur score avait déjà été optimisé à l'aide d'autres techniques. L'amélioration du score de test, bien que plus faible (0,7\%), indique que la progression réalisée est une réelle progression et non pas un résultat de sur-apprentissage de l'optimiseur. 

\begin{figure}[!h]
\centering
\includegraphics[scale=0.4]{data/asynceda1.pdf}	
\caption{AsyncEDA sur \textsc{BOINC}: Evolution du meilleur score en classification de chaque iteration pour la prédiction de la structure secondaire des protéines}
\label{asynceda1}
\end{figure}

\begin{figure}[!h]
\centering
\includegraphics[scale=0.4]{data/scoresMean.pdf}	
\caption{AsyncEDA sur \textsc{BOINC}: Evolution du score en classification moyen de chaque iteration pour la prédiction de la structure secondaire des protéines}
\label{scoresMean}
\end{figure}

\begin{table}[htdp]
\caption{Amélioration du score de validation et du score de test}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
 & validation & test\\
\hline
ancien meilleur score & 24,943099 \% & 25,231364 \%\\
nouveau meilleur score & 23,939306 \% & 24,453244 \%\\
\hline
\end{tabular}
\end{center}
\label{tabimprove}
\end{table}%


\chapter{Génie logiciel: intégration des EDA au sein de LBCpp et de \textsc{BOINC}}
\label{genie}

%\section{Prototype}
%\label{prototype}
% TODO parler de ça dans l'intrp

\section{Introduction: un \textit{framework} pour l'optimisation}
\label{frameworkintro1}
Les premières expérimentations réalisées à l'aide du prototype décrit dans la section~\ref{prototype} ont été très convaincantes. Aussi, il est apparu important de pousser l'intégration de \textsc{BOINC} encore plus loin afin d'en faciliter l'utilisation pour un chercheur. L'idée est de voir l'infrastructure \textsc{BOINC} comme une grille de calcul susceptible d'exécuter toutes sortes d'unités de travail et non pas comme un moyen d'exécuter une expérience particulière.

Parallèlement à cela, il semblait intéressant de découpler au maximum l'algorithme évolutionnaire utilisé pour générer les individus du contexte d'exécution qu'est \textsc{BOINC}, et ce afin de pouvoir utiliser l'EDA dans d'autres contextes d'exécution.

Actuellement, une partie importante des recherches menées par F. \textsc{Maes}, J. \textsc{Becker} et L. \textsc{Wehenkel} sont réalisées au sein d'une librairie C++ développée par F. \textsc{Maes}, J. \textsc{Becker}, LBCpp. Cette librairie a été choisie comme cadre de développement pour 3 raisons principales:
\begin{itemize}
\item Il s'agit d'une librairie dédiée à l'apprentissage et elle se prête donc bien à l'ajout d'un \textit{framework} pour l'optimisation.
\item Au moment de la réalisation, J. \textsc{Becker} était en train de mettre sur pied un module réseau au sein de LBCpp. Le but du module était de permettre facilement l'exécution de morceaux de code LBCpp sur le super-calculateur NIC3 de l'\textit{Institut Montefiore}. Il paraissait séduisant d'ajouter les fonctionnalités nécessaires pour réaliser la même chose avec l'infrastructure \textsc{BOINC}.
\item F. \textsc{Maes}, auteur principal de la librairie, convaincu par les premiers essais menés à l'aide du prototype était convaincu que ces ajouts serait un plus pour sa librairie.
\end{itemize}

Cette section a pour but de décrire le \textit{framework} d'optimisation qui a été développé. La section s'articule en deux parties bien distinctes:
\begin{itemize}
\item Une brève présentation du cadre de développement, la librairie LBCpp (section~\ref{LBCpp}).
\item Une présentation détaillée du \textit{framework} développé (section~\ref{frameworkintro}).
\end{itemize}

\section{Présentation de LBCpp}
\label{LBCpp}
\subsection{Aspects généraux}
LBCpp est une librairie d'apprentissage développée principalement par F. \textsc{Maes} mais également par J. \textsc{Becker}. Celle-ci est écrite en C++ mais dispose d'une sur-couche particulière. Cette sur-couche apporte principalement 2 améliorations par rapport au C++:
\begin{itemize}
\item Chaque classe, en plus d'être décrite dans son fichier \textit{.h}, est également partiellement ou totalement décrite par un fichier XML. Ces fichiers XML sont parsés à la compilation et utilisés pour générer du code permettant une certaine introspection des classes. A l'aide d'un typage un peu particulier, ce système permet par exemple de savoir combien de champs compte une classe mais également leur type. Ce système permet également très facilement la (dé)sérialisation d'objets.
\item Une structure maintient l'ensemble des références vers un objet créé grâce à l'opérateur \textit{new} si bien que celui-ci est supprimé automatiquement lorsqu'il n'est plus accessible. Attention cependant que les cycles ne sont pas détectés contrairement au fonctionnement du \textit{garbage collector} de Java !
\end{itemize}
Ces particularités, couplées à la richesse des fonctions disponibles dans la librairies rendent celle-ci très puissante mais un certain temps d'adaptation est nécessaire avant de pouvoir en tirer profit.

Les paragraphes suivants sont destinés  à présenter un peu plus en détails 3 aspects important de LBCpp qui ont été utilisés afin de réaliser le \textit{framework}.

\subsection{Aspects réseau}
Comme mentionné dans l'introduction de cette section, J. \textsc{Becker} est l'auteur d'une couche réseau au sein de LBCpp. Le but de cette couche est simple: permettre à un chercheur d'exécuter des morceaux de code LBCpp (WorkUnit LBCpp) sur NIC3. Ce travail ayant été réalisé, il n'a fallu ajouter que quelques éléments afin de gérer également \textsc{BOINC}.

La structure mise en place est illustrée à la Fig.~\ref{reseauLBCPP}. Le serveur \textit{Manager} est une entité qui permet de dispatcher le travail sur NIC3 ou sur le réseau \textsc{BOINC} (selon les désirs du chercheur) et de récupérer les résultats lorsque ceux-ci sont disponibles. Dans la configuration mise en place par J. \textsc{Becker}, le serveur \textsc{BOINC} et NIC3 sont des \textbf{clients} du \textit{Manager}. C'est donc à eux de contacter régulièrement le \textit{Manager}. C'est lors de ces échanges périodiques que le \textit{Manager} récupère les unités terminées. C'est également à ce moment là que le \textit{Manager} envoie les nouvelles requêtes, les nouvelles unités de travail.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{img/reseauLBCPP.pdf}	
\caption{Configuration réseau}
\label{reseauLBCPP}
\end{figure}


\subsubsection{\textsc{BOINC} \textit{work generator}}
Dans ce contexte, ce n'est plus la responsabilité du serveur \textsc{BOINC} de créer du travail. Celui-ci est récupéré directement chez le \textit{Manager}. Les unités récupérées sont stockées dans un dossier dédié qui est périodiquement scanné par le \textit{work generator} \textsc{BOINC}. Le rôle de ce programme n'est donc plus que de transmettre les unités sur le réseau \textsc{BOINC}. Ceci passe par la copie des fichiers dans la hiérarchie de répertoires \textit{download} et par l'appel de la fonction \textit{create\_work()} de l'API \textsc{BOINC} (voir section~\ref{workgeneratorboinc}). 

Le \textit{work generator} \textsc{BOINC} développé est donc finalement complètement indépendant de l'expérience de recherche menée. La seule restriction étant d'utiliser LBCpp.


\subsubsection{\textsc{BOINC} \textit{assimilator}}
Tout comme le \textit{work generator}, l'\textit{assimilator} \textsc{BOINC} peut désormais se réduire à sa plus simple expression compte tenu de l'architecture réseau déployée. L'exécution de l'\textit{assimilator} se contente de déplacer les fichiers \textit{output} dans un répertoire dédié et leur attribue un nom particulier. Lors de la communication avec le \textit{Manager} se dossier est alors scanné et les résultats présents sont envoyés au \textit{Manager}.

Ce programme est donc lui aussi complètement indépendant de l'expérience de recherche menée. Les résultats sont supprimés du serveur \textsc{BOINC} et archivés sur le \textit{Manager}. Les résultats restent accessibles au chercheur via le \textit{Manager}; libre à lui d'archiver les résultats autrement s'il le désire a posteriori.


\section{\textit{Framework} d'optimisation développé}
\label{frameworkintro}
Un \textit{Optimizer}, quelque soit son mode de fonctionnement, peut être vu comme une fonction dont la valeur de retour est le paramètre optimum d'une fonction objectif (ou \textit{fitness}) fournie en argument. Le concept de fonction étant déjà présent au sein de LBCpp, il était logique de faire dériver le concept d'\textit{Optimizer} de celui-ci.

Lorsque l'on parle de fonction, il est importante de préciser quels sont ses arguments et quel est sa valeur de retour. Le problème de la valeur de retour a déjà été abordé. En ce qui concerne les arguments, un argument au minimum est nécessaire: la fonction de \textit{fitness}~\footnote{Dans la suite, l'objectif d'un \textit{Optimizer} est de minimiser la fonction de \textit{fitness}.}. Parallèlement à cela, comme mentionné dans l'introduction~\ref{frameworkintro1}, le framework doit permettre de choisir le contexte d'exécution responsable d'évaluer les individus. Plutôt que de passer la fonction \textit{fitness} en argument de la fonction d'optimisation, un concept plus général d'\textit{OptimizerContext} a été défini et c'est une instance de ce concept qui est passée en argument à la fonction d'optimisation. La responsabilité principale de ce concept est de permettre l'évaluation d'individus. %TODO ref

Ce seul argument pourrait sembler suffisant, mais un deuxième argument est cependant nécessaire: une instance d'\textit{OptimizerState}. La nécessite de ce concept vient du fait qu'un processus d'optimisation est un tâche qui peut être relativement longue. Il est donc intéressant de pouvoir sauver l'état du processus afin de pouvoir arrêter celui-ci et le relancer à partir de l'état sauvegardé. Il est par exemple nécessaire de sauvegarder au minimum le meilleur score obtenu jusqu'à présent ainsi que la variable correspondante (les paramètres). Conceptuellement, l'évaluation d'une fonction n'a aucune raison de modifier l'état de celle-ci. Seuls des variables locales sont susceptibles d'être modifiées durant le processus d'évaluation. Ainsi, l'implémentation de la responsabilité \textit{compute(...)} d'une \textit{Function} est une fonction définie comme étant \textit{const}. Pour cette raison, l'état du processus d'optimisation ne peut être stocké au sein même du concept d'\textit{Optimizer} mais doit être stocké au sein d'un concept externe: l'\textit{OptimizerState}. Parallèlement à ces considérations, un nombre important d'algorithmes d'optimisation utilisent une connaissance \textit{a priori} au début du processus d'optimisation. Cette connaissance \textit{a priori}, dépendant du type d'\textit{Optimizer}, peut-être vue comme un attribut du concept d'\textit{OptimizerState}. %TODO ref
 
La Fig.~\ref{framework1} reprend sous forme de diagramme conceptuel statique (UML) les éléments principaux présentés. Dans la suite de cette section, l'implémentation des trois éléments principaux de cette structure sera détaillée ainsi que leurs spécialisations.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.7]{img/framework1.pdf}
\caption{\textit{Optimizer framework}: diagramme conceptuel statique}
\label{framework1}
\end{figure}

\subsection{Optimizer}
Il s'agit de la hiérarchie de classes implémentant la logique d'optimisation. Dans le cadre de ce travail, les algorithmes d'optimisation considérés sont de type évolutionnaires (voir section~\ref{evointro}) et se basent donc sur l'évolution d'une population. Plus précisément il s'agit d'EDA (voir section~\ref{edageneral}). Une classe abstraite reprenant les méthodes communes aux implémentations de ce type d'algorithmes a donc été créée. Il s'agit de la classe abstraite \textit{PopulationBasedOptimizer}. Deux implémentations de cette classe abstraite ont été réalisées: \textit{EDAOptimizer} et \textit{AsyncEDAOptimizer}. La Fig.~\ref{optimizerhierarchy} présente un diagramme de classes statique de cette hiérarchie.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.7]{img/optimizerhierarchy.pdf}
\caption{\textit{Optimizer}: diagramme de classes statique}
\label{optimizerhierarchy}
\end{figure}

\subsubsection{EDAOptimizer} 
Il s'agit de la version classique de l'EDA telle que décrite dans la section~\ref{edageneral}. L'implémentation réalisée permet l'utilisation de mixtures comme modèe (voir section~\ref{mixture}). Enfin, il est également possible de forcer l'introduction du meilleur individu actuel dans chaque nouvelle population.

\subsubsection{AsyncEDAOptimizer} 
Il s'agit de la version asynchrone de l'EDA classique. Celle-ci est présentée dans la section~\ref{edaasynch}. L'implémentation réalisée jouit des mêmes options que celle de l'\textit{EDAOptimizer}.  


\subsection{OptimizerContext}
\label{optimizecontextsection}
% TODO restructurer
Cette classe permet à un \textit{Optimizer} d'évaluer des individus. L'évaluation étant asynchrone (Fig.~\ref{framework1}), on parlera plutôt de requêtes d'évaluation puisque le score n'est pas retourné directement à l'appelant.

Le résultat n'étant pas retourné directement à l'appelant, une \textit{Callback} est utilisée et plus précisément une \textit{FunctionCallback}. L'\textit{Optimizer} doit, avant d'utiliser l'\textit{OptimizerContext} pour des évaluations, appeler la méthode \textit{setPostEvaluationCallback(...)} de la classe \textit{OptimizerContext}. Cette méthode permet de transmettre une référence vers l'instance de \textit{FunctionCallback} qu'il faut contacter une fois le résultat de l'évaluation obtenu. 

\textit{FunctionCallback} est une classe définissant deux fonctions destinées à être sur-chargées~\footnote{La classe n'est pas abstraite mais les implémentations par défaut consiste à ne "rien faire".}: \textit{functionCalled(...)} et \textit{functionReturned(...)}. Seul la fonction \textit{functionReturned(...)} présente un intérêt dans le cas qui nous occupe.

Dans le \textit{framework} développé, c'est l'\textit{OptimizerState} qui hérite de \textit{FunctionCallback} et qui implémente donc la méthode \textit{functionReturned(...)}. L'implémentation consiste simplement à stocker les résultats (\textit{pair<Double, Variable>}) dans un tableau (qui joue le rôle d'un \textit{buffer}) accessible par l'\textit{Optimizer}.

Il est également de la responsabilité de l'utilisateur de l'\textit{OptimizerContext} d'appeler la méthode \textit{removePostEvaluationCallback(...)} lorsque celui-ci a terminé d'utiliser l'\textit{OptimizerContext}.

Par défaut, les méthodes \textit{setPostEvaluationCallback(...)}/\textit{removePostEvaluationCallback(...)} se contentent d'ajouter/supprimer une \textit{callback} à l'instance de la fonction à optimiser. L'opération de \textit{callback} est donc directement réalisée au sein même de l'évaluation de la fonction (i.e. processus de \textit{callback} ne repasse pas par l'\textit{OptimizerContext} par défaut).

Le processus d'évaluation étant \textit{a priori} asynchrone, les méthodes \textit{waitUntilAllRequestsAreProcessed()} et \textit{areAllRequestsProcessed()} permettent à l'\textit{Optimizer} d'attendre que toutes les évaluations aient été effectuées~\footnote{Ceci est particulièrement utile pour l'implémentation de \textit{EDAOptimizer} par exemple.}. L'implémentation de \textit{waitUntilAllRequestsAreProcessed()} consiste simplement à boucler sur \textit{areAllRequestsProcessed()}. Celle-ci évite le \textit{busy-waiting} en mettant le \textit{thread} en sommeil entre chaque appel à \textit{areAllRequestsProcessed()}. La méthode \textit{getTimeToSleep()} permet au client de l'\textit{OptimizerContext} d'obtenir le laps de temps utilisé pour ces périodes de sommeil.

La Fig.~\ref{optimizercontext} reprend sous forme de diagramme de classes statique les points mentionnés ci-dessus. Trois implémentations de \textit{OptimizerContext} ont été réalisées. Celles-ci sont détaillées dans les paragraphes suivant.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.7]{img/optimizercontext.pdf}
\caption{\textit{OptimizerContext}: diagramme de classes statique}
\label{optimizercontext}
\end{figure}

\subsubsection{SynchroneousOptimizerContext} 
Il s'agit d'une version synchrone de l'\textit{OptimizerContext}. La méthode \textit{evaluate(...)} est donc bloquante et le retour de cette fonction s'effectue \textbf{après} le \textit{callback} renvoyant le résultat de l'évaluation.

\subsubsection{MultiThreadedOptimizerContext} 
Il s'agit d'une version asynchrone de l'\textit{OptimizerContext} s'appuyant sur le \textit{MultiThreadedExecutionContext} de LBCpp. Le processus de \textit{callback} ne passant pas par l'\textit{OptimizerContext}~\footnote{Comme expliqué dans la section~\ref{optimizecontextsection}, par défaut le \textit{callback} a lieu à la fin de l'évaluation de la fonction et contacte directement l'\textit{OptimizerState} sans passer par l'\textit{OptimizerContext}.}, une référence vers une variable entière est utilisée afin de connaître le nombre d'évaluations en cours dans le \textit{multi-threads pool}.

\subsubsection{DistributedOptimizerContext}
Il s'agit de l'\textit{OptimizerContext} permettant de distribuer les requêtes d'évaluations sur une grille de calcul (actuellement \textsc{NIC3} ou \textsc{BOINC}). L'implémentation de ce contexte est un peu plus délicate et se compose de deux parties.

La fonction \textit{evaluate(...)} est chargée de créer une \textit{WorkUnit} LBCpp à partir de la requête d'évaluation de la fonction~\footnote{Ceci est nécessaire puisque le Manager LBCpp traite uniquement des \textit{WorkUnit} LBCpp.}. Ceci est en réalité très simple à réaliser vu la présence de la classe \textit{FunctionWorkUnit} au sein de LBCpp qui \textit{wrappe} l'évaluation d'une fonction dans une \textit{WorkUnit}. Une fois l'unité créée, celle-ci est envoyée au Manager grâce à l'API \textit{Network} développée par J. \textsc{Becker}. Périodiquement, le serveur \textsc{BOINC} (ou \textsc{NIC3}) contacte le Manager LBCpp afin de récupérer les unités qui lui sont destinées afin de les calculer. Lors de ces contacts périodiques avec le Manager LBCpp, la grille de calcule renvoie également les résultats des unités terminées. Ces résultats sont alors stockés sur le Manager LBCpp.

Le deuxième rôle du \textit{DistributedOptimizerContext} est de récupérer les résultats présents sur le Manager LBCpp afin de transmettre ceux-ci à la \textit{FunctionCallback} (i.e. l'\textit{OptimizerState}). Pour ce faire, à chaque instance de \textit{DistributedOptimizerContext} est associé une instance de \textit{GetFinishedExecutionTracesDaemon}. Il s'agit d'une classe dérivant de \textit{Thread} dont le but est de récupérer périodiquement les résultats disponibles sur le Manager LBCpp et d'appeler la \textit{FunctionCallback} spécifiée par l'utilisateur une fois le résultat récupéré.

Afin de réaliser ces tâches, les instances de \textit{DistributedOptimizerContext} et de \textit{GetFinishedExecutionTracesDaemon} ont toutes deux accès (en lecture et en écriture) à une structure de données maintenant les requêtes en cours d'évaluation. Les opérations des deux classes s'effectuant dans deux \textit{threads} différents il faut bien entendu une certaine synchronisation entre les deux. La librairie \textit{Juce} fournit un moyen très simple (similaire à ce qui se fait en Java) pour introduire cette synchronisation à l'aide d'un objet "verrou" (\textit{CriticalSection}).

La Fig.~\ref{distributedoptimizercontext} reprend sous forme de diagramme de classes statique les points mentionnées ci-dessus concernant le \textit{DistributedOptimizerContext}.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.7]{img/distributedoptimizercontext.pdf}
\caption{\textit{DistributedOptimizerContext}: diagramme de classes statique}
\label{distributedoptimizercontext}
\end{figure}

\subsection{OptimizerState}
Il s'agit de la classe responsable de stocker l'état d'un \textit{Optimizer}. En effet, comme expliqué dans l'introduction de cette section, l'état d'un \textit{Optimizer} ne peut directement être stocké dans celui-ci. 

L'état d'un \textit{Optimizer} contient principalement:
\begin{itemize}
\item Le nombre total de requêtes d'évaluation effectuées (\textit{totalNumberOfRequests}) et le nombre total de résultats obtenus (\textit{totalNumberOfResults}). La différence entre ces deux nombres étant le nombre d'évaluations en cours.
\item Une structure contenant les résultats obtenus mais qui n'ont pas encore été traité par l'\textit{Optimizer} (\textit{processedRequests}). Comme expliqué dans la section consacrée à l'\textit{OptimizerContext}, cette structure est remplie via la \textit{callback} appelée à la fin de l'évaluation de la fonction à optimiser.
\item Le meilleur score obtenu jusqu'à présent ainsi que la variable associée.
\item Un verrou \textit{Juce} permettant de synchroniser les accès à l'état puisque ceux-ci peuvent se faire depuis des \textit{threads} différents.
\end{itemize}

Grâce à la sur-couche de LBCpp (section~\ref{LBCpp}), cette classe est facilement sérialisable en XML afin de sauvegarder l'état de l'\textit{Optimizer} en vue de pouvoir le redémarrer. 

En pratique, il est intéressant de pouvoir sauvegarder l'état de manière régulière sans toute fois perdre trop de temps processeur pour la sauvegarde. Ainsi, le programmeur utilisant cette classe afin de coder un \textit{Optimizer} est invité à appeler la fonction \textit{autoSaveToFile(...)} de manière régulière (à des moments où l'état est cohérent). Un paramètre utilisé lors de l'instanciation d'un \textit{OptimizerState} permet de fixer la fréquence maximale de sauvegarde, si bien que la sauvegarde ne sera effective que si un certains laps de temps minimum s'est écoulé depuis la dernière sauvegarde, empêchant ainsi de gaspiller trop de temps processeur. L'utilisateur de cette fonction peut également contourner se mécanisme à l'aide d'un \textit{flag} booleén (ceci peut-être utile en fin de procédure d'optimisation par exemple afin de forcer la sauvegarde de l'état). 

Le diagramme de classes statique de la Fig.~\ref{optimizerstate} reprend les éléments principaux concernant la classe \textit{OptimizerState}.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.7]{img/optimizerstate.pdf}
\caption{\textit{OptimizerState}: diagramme de classes statique}
\label{optimizerstate}
\end{figure}

\subsubsection{SamplerBasedOptimizerState} 
Dans le travail réalisé, les \textit{Optimizer} sont de type EDA et sont donc basés sur la constructions de distributions de probabilité (voir section~\ref{edageneral}). La hiérarchie de classes \textit{Sampler} de LBCpp se prête particulièrement à cette représentation de distributions. En effet, l'interface de \textit{Sample} comprend deux méthodes principales (Fig.~\ref{optimizerstate}):
\begin{itemize}
\item \textit{learn(...)}: permet d'apprendre une distribution sur base d'un ensemble d'échantillons.
\item \textit{sample(...)}: permet de tirer aléatoirement un échantillon suivant la distribution représentée.
\end{itemize}
Ces deux méthodes permettent d'implémenter facilement des algorithmes de type EDA. A côté des \textit{Sampler} classiques du type gaussien, Bernoulli, ensemble de probabilités associées à un type énuméré, ..., la librairie LBCpp comprend également des \textit{Sampler} composite permettant de combiner des \textit{Sampler} entre eux. Ainsi, la classe \textit{MixtureSample} est par exemple utilisée afin d'implémenter le mécanisme de mixture de distributions décrit dans la section~\ref{mixture}.

% TODO diagramme de séquence pour utiliser Optimizer

\section{Intégration à l'\textit{Explorer} de LBCpp}
La librairie LBCpp présentée rapidement dans la section~\ref{LBCpp} dispose également d'une interface graphique, l'\textit{Explorer}. Celui-ci permet de visualiser en temps réel la trace d'exécution d'un morceau de code LBCpp. Pour ce faire, le code doit faire appel à certaines fonctions telles que: \textit{informationCallback, resultCallback, progressionCallback, ...} Ces appels permettent de décrire l'avancement du programme et les résultats obtenus. Ces informations sont utilisées pour un affichage en console, mais également pour générer une trace d'exécution (\textit{ExecutionTrace}). C'est, entre autre, cette trace d'exécution que permet de visualiser le Manager. 

Une autre fonctionnalité intéressante du Manager est qu'il permet en quelques clics d'obtenir des courbes à partir des résultats fourni via les \textit{callbacks}.

Ainsi, cette API a été utilisée dans l'implémentation du \textit{Optimizer framework} afin que l'exécution des \textit{Optimizer} soit aussi bien intégrée que possible au sein de l'\textit{Explorer} et permettent notamment de visualiser directement les courbes de progression de l'optimisation. Le résultat est visible Fig.~\ref{explorer}.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.3]{img/explorer.png}
\caption{\textit{OptimizerState}: diagramme de classes statique}
\label{explorer}
\end{figure}


\chapter{Perspectives et conclusions}


% TODO gestion des fichiers sous BOINC
% TODO vérifier que tt les .cpp cité sont sur svn
% TODO utiliser les anciennes images de présentation du TFE
% TODO images top ou bottom
% TODO remerciements
% TODO annexes ac les liens utiles 


\newpage
\nocite{*}
\bibliographystyle{plain}
\bibliography{biblio}


\end{document}


%\chapter{TODO: not restructured yet}

%
%% TODO unzipper
%\section{BoincEvaluator}
%\subsection{Introduction et objectif}
%Le nom attribué à la première expérience d'apprentissage réalisée via \textsc{BOINC} est \textit{BoincEvaluator}.

%\subsection{Implémentation}
%Dès le début du travail il est apparu évident qu'il fallait concevoir les choses de manière aussi générique que possible. Ainsi, il était important de concevoir les choses de manière à ce que \textsc{BOINC} soit un moyen pour un chercheur d'exécuté une expérience "quelconque" et non pas un moyen d'exécuter une expérience particulière. Un langage basé sur XML a donc été défini afin de décrire/définir une expérience d'optimisation. Les éléments contenu dans cette description sont les suivants:
%\begin{itemize}
%\item Le nom du programme devant être exécuté par le \textit{wrapper} ainsi que les arguments à lui passer.
%\item Le nom de l'archive \textit{zip} contenant les données utilisées pour l'apprentissage et l'évaluation. %TODO unzipper
%Cette archive sera une unique fois chez le client via l'application \textit{unzipper}.
%\item La description des paramètres devant se trouver dans le fichier \textit{input.xml} à fournir au \textit{worker} (i.e. la description de l'ensemble des paramètres à utiliser). Cette description comprend deux parties:
%	\begin{itemize}
%	\item La déclaration d'un ensemble de catégories. Il s'agit de la définition de types énumérés. % TODO exemple
%	\item L'ensemble des paramètres proprement dit. Chaque paramètre est décrit par un nom et un type. Le type est soit un type énuméré définit dans la section "catégories", soit un type "primitif" (\textit{numeric} pour les réels et \textit{integer} pour les entiers).  Pour les paramètres de type primitif il faut également préciser des bornes pour le paramètre (\textit{min} et \textit{max}). Enfin, il est possible de fournir une information \textit{a priori} pour l'EDA, sous forme de la moyenne et/ou de l'écart type pour les paramètres numériques et sous formes de probabilités pour les types énumérés.
%	\end{itemize}
%\item Le nom du score devant être extrait du fichier \textit{output} généré par le \textit{worker}.
%\item Le nom des fichiers permettant de gérer l'avancement de l'unité de travail dans le \textsc{BOINC} Manager. %TODO factiondone, state
%\end{itemize}
%Comme souvent avec les langages basés sur XML, la compréhension de ceux-ci par un lecteur est immédiate. C'est pourquoi le langage ne sera pas détaillé. % TODO nom du fichier à regader

%% TODO format fichier input et output

%\subsection{Work Generator}
%L'application qui génère les unités de travail est un EDA. Les paramètres sont considérés comme étant indépendant. L'EDA va alors associer à chaque paramètre numérique une moyenne et un écart type. Pour les paramètres de type énuméré, l'EDA va associer une probabilité à chaque élément de l'énumération. Pour reprendre le vocabulaire employé à la section %TODO
%, chaque jeu de paramètres généré par l'EDA est un individu. Chaque jeu de paramètres permet de créer une unité de travail \textsc{BOINC} (\textit{Work Unit}, WU) qui sera évaluée par les volontaires. 

%Dans les versions classiques d'EDA, % TODO sources
%l'algorithme génère une population de taille fixe, évalue chaque individu puis met à jour la distribution de probabilité sur base des meilleurs résultats afin de générer une nouvelle population. Cette approche n'est pas applicable en pratique au cas de \textsc{BOINC} à cause des temps de latence. En effet, imaginons que 100 unités sont distribuées sur le réseau \textsc{BOINC}, il faudrait attendre que ces 100 unités aient été évaluées avant de pouvoir générer d'autres unités. Le problème vient du fait que les résultats d'évaluation ne parviendront avec un délais très variable au serveur (suivant l'hôte sur lequel l'évaluation à lieu notamment). Cette approche serait donc très efficace puisque l'EDA passerait énormément de temps à attendre les dernières évaluations. 

%La solution à ce problème est de mettre au point une version asynchrone d'un EDA. %TODO déjà fait qq part ?
%La section suivante vise à décrire l'EDA implémenté.

%\subsubsection{EDA Asynchrone: première version}
%La première chose à considérer est la distribution initiale à utiliser dans le cas où aucune information a priori n'est fournie:
%\begin{itemize}
%\item Pour les types énumérés une probabilité uniforme est utilisée. % TODO + précis
%\item Pour les types numériques la moyenne est estimée par la relation $\frac{min + max}{2}$ et l'écart type par la relation $\frac{\textnormal{max}(abs(mean-min), abs(mean-max))}{3}$.
%\end{itemize}

%A partir de cette distribution initiale le \textit{work generator} va générer et envoyer pour évaluation sur le réseau \textsc{BOINC} un certain nombre d'unités (population initiale). Ensuite, le générateur va maintenir un nombre constant d'évaluations en cours. Se pose alors là question de comment est mis à jour la distribution ou en d'autres termes comment sont générées les unités suivantes. Afin de répondre à cette question, il faut savoir que tous les résultats (score associé à chaque individu) sont stockés dans une base de donnée. A chaque fois que l'EDA doit générer de nouveaux individus, la distribution utilisée est construite sur base des $x\%$ meilleurs résultats obtenus jusqu'à présent (ceux-ci sont extrait de la base de données). Bien entendu, cette politique de mise à jour de la distribution n'est pas appliquée tout de suite, celle-ci ne prend effet que lorsqu'un nombre suffisant de résultas sont disponbiles.

%\subsubsection{Implémentation}
%Ce programme a été réalisé rapidement afin de pouvoir tester la pertinence de l'approche et l'utilité de \textsc{BOINC}, son implémentation n'est donc pas soignée et ne sera pas détaillée dans ce rapport.

%L'implémentation se base notamment sur la librairie \textit{juce}. Cette librairie contient un parser XML relativement simple à utiliser. Celui-ci est utilisé afin de parser le fichier \textit{application.xml} décrivant l'expérience d'optimisation (cf. %TODO)
%La fonction \textit{parseApplicationFile()} permet notamment de récupérer le nom de l'application et un pointeur vers le \textit{XmlElement} décrivant la liste des paramètres. L'exécution de cette méthode permet également de remplir une map associant à chaque nom de type énuméré défini un pointeur vers une instance de la classe \textit{Category} décrivant le type. Une telle instance contient notamment deux vecteurs:
%\begin{itemize}
%\item un contenant les noms de l'énumération.
%\item un contenant les probabilités associées à chaque valeur de l'énumération~\footnote{La correspondance est réalisée grâce aux indices des vecteurs}.
%\end{itemize}

%La deuxième partie intéressante du programme est l'EDA proprement dit qui, comme expliqué %TODO
%, repose sur une base de données. L'implémentation est donc réalisée grâce à l'API MySQL. La première chose à calculer est le nombre de résultats à utiliser pour l'estimation de la distribution. Ici l'algorithme utilise un certain pourcentage du nombre total de résultats disponibles. Afin de déterminer le nombre de résultats disponibles la requête MySQL suivante est utilisée:%TODO dire que name est le nom du paramètre
%$$\textnormal{SELECT count(*) from results\_sorted}$$
%Une fois le nombre de résultats à utiliser déterminé ($nb$), il s'agit d'extraire la moyenne et la déviation standard pour les paramètres numériques. Ceci est réalisé grâce à la règle suivante:
%$$\textnormal{SELECT AVG(}name\textnormal{), STDDEV\_POP(}name\textnormal{) FROM (SELECT * from results\_sorted limit }nb\textnormal{) a}$$ % TODO mise en page
%La table \textit{results\_sorted} est une vue triée par score de la table \textit{results}. L'utilisation d'une vue permet de réduire la charge de calcul puisqu'il ne faut pas trier la table à chaque exécution.

%En ce qui concerne les types énumérés, l'estimation de la distribution au sein des $nb$ meilleurs résultats est réalisées grâce à la requête:
%$$\textnormal{SELECT }name\textnormal{, count(*) as }nb\textnormal{ from (select * from results\_sorted limit }nb\textnormal{) a group by }name$$

%\subsection{Validator}
%%TODO voir sertion...
%La validation se base sur le score se trouvant dans le fichier \textit{output} de l'unité de travail. Le rôle de la fonction \textit{init\_result()} implémentée est donc d'extraire le score grâce au parser XML se trouvant dans la librairie Juce.

%La fonction \textit{compare\_results()} effectue simplement la comparaison des scores. Afin de tenir compte des éventuels différences dues à l'exécution sur un processeur 32 bits ou 64 bits, la comparaison n'est pas un simple test d'égalité mais fait intervenir une certaine marge de tolérance.

%Une fonctionnalité supplémentaire à été ajoutée à ce \textit{validator}: l'archivage des résultats invalides. Il s'agit d'un double archivage:
%\begin{itemize}
%\item Archivage des fichiers \textit{output} invalides dans un dossier dédié (\textit{invalids}).
%\item Insertion dans une table (\textit{invalids}) de la base de donnée associée à l'expérience des informations relatives aux résultats invalides (paramètres de l'unité de travail associée, noms des deux résultats, les deux scores, la date ainsi que les identifiants des hôtes qui ont calculé ces résultats).
%\end{itemize}
%Cet archivage peut paraître inutile mais il est en fait très pertinent afin d'aider au debug de l'application client.

%% TODO section dédiée à Juce ?
%\subsection{Assimilator}
%Le programme implémenté se comporte de la sorte:
%\begin{itemize}
%\item Si un résultats canonique existe, le fichier \textit{output} correspondant est copié de la hiérarchie des répertoires upload vers un répertoire dédié (\textit{results}) et le résultat est inséré dans la table \textit{results} de la base de données dédiée à l'expérience. Cette table reprend le nom de la WU, l'ensemble des paramètres utilisés, le score obtenu et la date. % TODO parler de upload avant
%% TOOD numéro de version ?
%\item S'il n'y a pas de résultat canonique (WU problématique), un comportement similaire est adopté mais avec les données d'\textit{input} uniquement, i.e le fichier \textit{input} est copié dans un répertoire particulier (\textit{error\_results}) et les paramètres  de cette WU (ainsi que le nom et la date) sont introduit dans une table de la base de données (\textit{errors}).
%\end{itemize}

%\subsection{Remarques}
%Il est primordial de comprendre que l'implémentation réalisée pour ces 3 programmes n'est pas une version finale. Il est cependant important de parler de celle-ci pour plusieurs raisons:
%\begin{itemize}
%\item Cela permet d'introduire les concepts utilisés dans ce travail.
%\item Cela permet de voir la méthodologie suivie durant le travail. % TODO maintenant plus rien à avoir ac ça
%\end{itemize}

%% TODO nuancer
%Ces implémentations ont été réalisées très rapidement et avaient pour but de tester la faisabilité du projet et de réaliser une première expérience d'optimisation sous \textsc{BOINC}.

%Alors que le \textit{work generator} réalisé est relativement général puisqu'il s'appuie sur le fichier \textit{application.xml} décrivant l'expérience d'optimisation à réaliser, le \textit{validator} et l'\textit{assimilator} sont eux spécifiques à l'application. Il serait tout à fait possible de rendre ceux-ci génériques en se basant sur le \textit{application.xml} mais ceci n'a pas été fait car, comme je l'expliquerai dans la suite de ce rapport, une autre approche encore plus générique à finalement été suivie.

%
%\subsection{Résultats}
%Dans cette section sont présentés les différents résultats obtenus grâce à cette première expérience. % TODO etoffer
%Pour cette première expérience le projet est resté "privé" et seul une poignée de volontaires avait accès au projet.

%\subsubsection{Manque de déterminisme}
%L'exécution du learner developpé par Francis Maes sur plusieurs machines différentes grâce à \textsc{BOINC} a permis de mettre au jour deux sources de non déterminisme:
%\begin{itemize}
%\item L'ordre des opérations dans la sérialisation XML. Ceci conduisait à des fichiers \textit{output} parfois dont le contenu était identique, mais dont l'ordre du contenu variait. Cette situation a été détectée grâce à la toute première version du \textit{validator} qui était en fait un des deux \textit{validator} exemples fourni avec le serveur \textsc{BOINC}. Celui-ci effectue une comparaison byte à byte des fichiers \textit{output} afin de déterminer si deux résultats sont identiques.
%\item L'ordre du chargement des fichiers décrivant les protéines (dataset) ce qui conduit à de légère différences au niveau du score.
%\end{itemize}

%\subsubsection{Paramètres invalides}
%Rapidement des scores nuls sont apparus dans la table contenant les résultats, signe d'un bug dans la routine d'évaluation; bug qui n'avait jusqu'à alors pas été détecté. La section %TODO
%détaille comment \textsc{BOINC} a facilité la tâche d'identification de la cause du bug.


%\subsubsection{Page de statistiques}
%Une fois les bugs des sections  %TODO
%découvert, il fût important de mettre en place un système permettant de détecter facilement la cause du bug. Ceci a été rendu possible grâce à la base de données contenant non seulement les résultats valides, mais également les résultats non valides.

%%TODO pages dans le code ?
%J'ai rapidement mis en place un outil (sous la forme de pages \textit{php}) permettant d'explorer ces bases de données facilement. %TODO URL
%L'outil permet de sélectionner un pourcentage variable des meilleurs ou des pires résultas et affiche la distribution associée pour chaque paramètre.

%La sélection des 0.7\% pire résultats conduit à ne considérer que les résultats dont le score est de 0, i.e. les unités ayant conduit à un bug dans la phase d'évaluation. En comparant les distributions obtenues ces unités avec les distributions obtenues avec l'ensemble complet des résultats, la cause du bug est détectable très facilement:
%% tableau ac multiClassInference pour les deux cas
%J'ai ainsi pu communiquer à Francis Maes que la source du bug était à chercher dans le cas où %TODO one against all
%était utilisé alors que je n'avais que très peu de connaissances concernant l'implémentation du programme.

%L'analyse des distributions obtenues avec les meilleurs résultats a également apporté deux résultats importants:
%\begin{itemize}
%\item Les probabilités obtenues pour les paramètres booléens sont toutes de 50/50. Ceci peut paraître surprenant de prime abord, mais il s'avère que ces paramètres n'étaient pas utilisé par la première version du learner. L'optimizer a donc su mettre en évidence des paramètres inutiles!
%\item Francis Maes a analysé les distributions et a pu constater que les certains paramètres avaient probablement convergé trop rapidement. Ceci s'explique par le fait qu'il n'y avait aucun mécanisme permettant de conserver un certain caractère aléatoire dans la première version de l'EDA. Or les EDA essayent en général toujours de garder une partie non déterministe afin d'éviter de converger trop rapidement vers un maximum local (au lieu du maximum global). Pour reprendre le parallèle avec l'évolution, il s'agit des mutations que subissent les individus. Dans la section %TODO
%, les modifications permettant de freiner la convergence seront abordées.
%\end{itemize}

%
%\subsubsection{L'EDA en action}
%La figure %TODO
%présente l'évolution du score moyen au cours de l'expérience. Le score moyen est calculé à l'aide des résultat reçu pendant les 12 dernières heures. L'évolution croissante de la courbe montre clairement que l'EDA fonctionne; la distribution utilisée pour générer les unités tend à générer de meilleurs candidats. La courbe bleu représente l'évolution du score moyen en excluant les scores nul (résultats bugés) tandis que la courbe rouge inclus ces résultats. Fort heureusement, l'allure de la courbe est similaire dans les deux cas. Il est également important de remarquer que l'écart entre la courbe bleu et la courbe rouge tend à se réduire, ce qui démontre encore une fois le fonctionnement de l'EDA; celui-ci tend à exclure les scores nuls.

%\begin{figure}[!h]
%\centering
%\includegraphics[scale=0.5]{img/boincevaluator1_avg.pdf}
%\caption{Evolution du score moyen (sur 12h) pendant 60h}%TODO}
%\label{boincevaluator1_avg}
%\end{figure}

%La figure %TODO
%présente l'évolution du score maximal obtenu pendant la période de 12h considérée. Mis à part la valeur relevée à l'itération 2 %TODO
%qui semble anormalement élevée (probablement un "coup de chance"), on peut constater que le score maximum semble évoluer de manière croissante ce qui confirme encore une fois le bon fonctionnement de l'EDA.
%\begin{figure}[!h]
%\centering
%\includegraphics[scale=0.5]{img/boincevaluator1_max.pdf}
%\caption{Evolution du score max (toutes les 12h) pendant 60h}%TODO}
%\label{boincevaluator1_avg}
%\end{figure}
%%TODO légende des graphiques
%%TODO commentaires

%
%% TODO : numéro svn pour faciliter le debug

%
%\section{BoincEvaluator2}
%%TODO site web ?
%Après correction par Francis Maes des différents bug trouvés dans l'application, j'ai mis en place une deuxième simulation sous \textsc{BOINC}. Celle-ci, contrairement à la première a été réalisée avec un nombre plus important d'utilisateurs puisque le projet a été rendu public pour l'occasion.

%J'ai également légèrement modifié le \textit{work generator} afin d'empêcher une convergence trop rapide de l'EDA vers un minimum local:
%\begin{itemize}
%\item La déviation standard utilisée pour générer les paramètres numériques est désormais égale à deux fois la déviation standard calculée via les meilleurs résultats.
%\item Les paramètres de type énuméré sont parfois générés sans mettre à jour la distribution. %TODO mieux expliquer
%\end{itemize}

%\subsection{Résultats}

%\subsubsection{Bugs}
%Cette expérience a permis de découvrir 2 bugs restant au sein de l'application client: présence de scores nuls et présence de scores égaux à l'unité!

%Le premier phénomène avait déjà été observé lors de la première expérience et le problème était sensé être résolu (grâce aux patchs de Francis Maes). Cette expérience a permis de montrer qu'il subsistait un problème.

%Le deuxième phénomène était quant à lui nouveau. Un score de 1 étant bien entendu impossible il ne pouvait s'agir que d'un bug. A nouveau l'outil statistique, sous forme de pages php, a permis au chercheur de trouver rapidement la source du problème.

%%TODO dire que les pages php pourraient être généralisées 

%\subsubsection{L'EDA en action}
%La figure %TODO
%est l'analogue de la figure %TODO
%présentée à la section %TODO.
%La courbe comporte deux phases:
%\begin{itemize}
%\item Une phase croissante.
%\item Un palier.
%\end{itemize}
%La phase croissante est le comportement attendu, c'est l'effet espéré de l'EDA. Il est intéressant de remarquer que cette croissance est cependant moins rapide que dans l'expérience ce qui s'explique (en partie du moins) par le système de "freinage" de l'EDA mis en place. %TODO cf
%Obtenir un palier est un comportement attendu. En revanche, le palier apparait ici bien trop tôt (score moyen de 0.45 seulement) et ce palier est bien trop brusque. Il y a cependant une explication plausible à ce phénomène. La date stockée dans la base de données des résultats est la date de \textbf{réception} du résultat et non pas la date de \textbf{création} de l'unité. Aussi cette expérience à été prématurément arrêtée (aux alentours de )%TODO
%puisque l'application contenant toujours certains bugs (cf. )~\footnote{Un projet sérieux se doit d'empêcher le gaspillage de la puissance de calcul.} %TODO
%De plus, comme expliqué précédemment, la latence entre la création d'une unité et la réception du résultat est très variable. Certains hôtes sont presque entièrement dédié au projet \textit{Evo@home} alors que d'autres calculent sur des dizaines de projets. Il est donc probable que les résultats obtenu après %TODO
%correspondant à de "vieilles" unités qui ont mis un temps plus important à être calculé. Ceci soulève un point important: stocker la date de \textbf{réception} plutôt que la date de \textbf{création} était une erreur de conception. Utiliser la date de réception fausse légèrement les résultats.

%\begin{figure}[!h]
%\centering
%\includegraphics[scale=0.5]{img/boincevaluator2_avg.pdf}
%\caption{Evolution du score moyen (sur 12h) pendant 72h}%TODO}
%\label{boincevaluator2_avg}
%\end{figure}

%La figure %TODO
%présente l'évolution du pourcentage de résultats nuls obtenu sur une période de temps fixée. Encore une fois, on peut constater que l'EDA effectue correctement son travail puisque ce pourcentage à tendance à diminuer.

%\begin{figure}[!h]
%\centering
%\includegraphics[scale=0.5]{img/boincevaluator2_zero.pdf}
%\caption{Evolution du \% de résultats nuls (sur 12h) pendant 72h}%TODO}
%\label{boincevaluator2_zero}
%\end{figure}


%\subsection{LBCpp, les librairies dynamiques et BOINC}
%Alors que le premier learner développé par Francis Maes était lié de manière statique à LBCpp et à Juce, ce n'est en principe pas la façon de procéder lorsqu'on programme au sein de LBCpp. En effet, la librairie LBCpp est normalement compilée sous forme d'une librairie dynamique, elle même liée dynamiquement à Juce. De plus, LBCpp se compose d'un coeur (\textit{lbcpp-core.so}) et de modules annexes sous forme de librairies dynamiques (\textit{libproteins.so} par exemple) chargés dynamiquement lorsque l'exécutable le requiert.

%Ainsi, il était intéressant de permettre ce mécanisme au sein de \textsc{BOINC}: distribuer les librairies dynamiques et l'exécutable plutôt qu'un simple exécutable lié statiquement. Bien que la chose semble aisée à mettre en oeuvre quelques difficultés ont été rencontrées en pratique à cause des différences de gestion des librairies dynamiques selon les systèmes d'exploitation et en particulier la variable indiquant où chercher les librairies dynamiques requises pour un exécutable. Il s'agit de la variable \textit{LD\_LIBRARY\_PATH} sous Linux et \textit{DYLD\_LIBRARY\_PATH} sous Mac OS. 

%%TODO avoir parlé de ça avant
%Malheureusement, le fichier XML utilisé par le wrapper ne permettait pas de spécifier ces variables. Afin de contourner le problème, j'ai donc écrit deux scripts shell dont le but était de modifier ces variables avant de lancer l'exécution du worker (les script retourne bien entendu la valeur retournée par l'exécution du worker). Cependant, cette solution étant peu pratique et pouvant mener à des failles de sécurité, j'ai contacté les développeurs de \textsc{BOINC} via leur mailing list afin de suggérer une modification du wrapper permettant de facilement modifier ces variables. L'idée étant intéressante et la communauté de développeurs étant très réactives, l'amélioration a été intégrée au code de \textsc{BOINC} quelques jours plus tard. % TODO liens

%
%\section{Première expérience au sein de LBCpp}

%\subsection{Introduction et objectif}
%Après avoir mis en place la partie réseau reliant le serveur \textsc{BOINC} au \textit{Manager}, il était important de tester/debuger celle-ci. Afin de faire d'une pierre deux coups, ces opérations ont été réalisée en même temps qu'une nouvelle opération d'optimisation.

%Le but de cette nouvelle expérience était de  ...

%\subsection{Les distributions}
%Comme mentionné à la section %TODO
%, la librairie dispose d'un type d'objet pour représenter les distributions. Il était donc naturel d'utiliser cette classe pour représenter la distribution apprise par un EDA. 

%En particulier, la librairie dispose d'une classe \textit{IndependentMultiVariateDistribution}. Comme son nom l'indique, cette classe représente une distribution multi-variée ou chaque variable est indépendante. Comme pour la première expérience (cf )%TODO
%l'EDA utilisé dans cette expérience considère que les paramètres à optimiser sont indépendant. C'est donc cette distribution qui sera utilisée.

%La classe \textit{Distribution} au sein de LBCpp est en réalité un template dont le paramètre est le type d'objets que doit renvoyer la méthode \textit{sample()}. Grâce à l'introspection disponible au sein de LBCpp il est donc possible d'instancier une distribution multi-variée indépendante qui renverra lorsqu'elle sera samplée %TODO
%une instance d'une classe éventuellement complexe définie par le programmeur. En effet, l'introspection permet d'avoir accès au nombre de champs contenu dans une classe ainsi qu'à leur type. La distribution multi-variée associe donc chacune de ses sous-distributions à une variable de la classe template %TODO
%%TODO graphique

%Comme dans l'expérience précédente, on attribue une distribution gaussienne à chaque paramètre numérique. Cependant, certains de ces paramètres numériques doivent être entier ce qui ne correspond pas à une distribution gaussienne classique. J'ai donc mis en place deux classes ()%TODO
%héritant de \textit{GaussianDistribution} mais renvoyant uniquement des entiers/des entiers positifs.

%Parallèlement à la hiérarchie de classes \textit{Distribution} existe une hiérarchie \textit{DistributionBuilder} (incomplète) utilisée afin de construire/d'apprendre une distribution. Dans le cas simple d'une distribution gaussienne, il est possible d'ajouter des éléments (des réels) au builder progressivement. Une fois tous les éléments ajouté, l'appel à la méthode \textit{build(...)} renvoie la \textit{GaussianDistribution} qui correspond à l'ensemble des éléments ajoutés. Cette fonctionnalité est très intéressante et je l'ai un peu étendue avant de m'en servir. J'ai entre autre créé la classe \textit{IndependentMultiVariateDistributionBuilder} qui permet comme son nom l'indique d'apprendre une distribution multi-variée indépendante. Afin de relier les deux hiérarchies j'ai également ajouté une méthode usine %TODO verifier
%à la hiérarchie \textit{Distribution}. Celle-ci permet d'obtenir le builder à utiliser pour une distribution particulière (\textit{createBuilder()}.

%%TODO graphique

%
%\subsection{Nouvel EDA Asynchrone}
%L'EDA Asynchrone implémenté pour cette expérience diffère de celui décrit à la section; le seul point commun étant qu'il soit asynchrone. %TODO

%La boucle principale de l'optimiseur effectue les opérations suivantes:
%\begin{itemize}
%\item Génération d'individus à évaluer (si nécessaire) et envoie des requêtes correspondantes au \textit{Manager}.
%\item Récupération des résultats disponibles sur le \textit{Manager}.
%\item Mise à jour de la distribution si assez de résultats disponibles.
%\end{itemize}
%% TODO schéma ?

%La différence principale réside dans le processus de mise à jour. Ici, la distribution n'est pas calculée sur l'\textbf{ensemble} des meilleurs résultats obtenus depuis le début de la simulation, mais sur l'ensemble des meilleurs résultats obtenus depuis la dernière mise à jour! Ceci correspond un peu plus à un EDA classique.

%Concernant la politique de "freinage" de l'EDA, celle-ci est également différente. Ici, un genre de filtre exponentiel %TODO
%est utilisé pour la mise à jour de la distribution. Concrètement, la formule suivante est utilisée:
%$$distribution = distribution + updateFactor * newDistribution$$
%où \textit{newDistribution} est la distribution calculée sur base des meilleurs résultats de cette itération et où \textit{updateFactor} est le terme permettant de contrôler le filtre exponentiel (à quel point faut-il favoriser la nouvelle distribution). Toute ces opérations de construction de distribution sont rendues très facile grâce au concept de \textit{DistributionBuilder}.


%\subsubsection{Détection d'un bug}
%% TODO parler de evo_ops avant
%Cette nouvelle expérience sur le réseau \textsc{BOINC} a permis de mettre au jour un bug qui était jusqu'alors passé inaperçu. En effet, la page d'administration du serveur \textsc{BOINC} a permis d'observer un taux de plantage de presque 40\% sur les machines équipées de Linux alors que le pourcentage était inférieur à 10\% pour les autres systèmes d'exploitation.

%Après quelques recherches dans les \textit{logs} du serveur et un certain dialogue avec les volontaires ()%TODO)
%, il est apparu qu'il s'agissait d'un bug se manifestant ou non de manière aléatoire: le programme ne plantait pas sur 40\% des machines Linux, mais plantait 40\% du temps sur la plupart des machines Linux.

%Francis Maes étant dans l'impossibilité de reproduire le bug sur sa machine, c'est un travail d'équipe qui a permis de finalement isoler la cause du bug et de corriger celui-ci. %TODO préciser le problème ?





