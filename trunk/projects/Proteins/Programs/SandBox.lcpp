/*-----------------------------------------.---------------------------------.
| Filename: SandBox.lcpp                   | Test Learning                   |
| Author  : Francis Maes                   |                                 |
| Started : 08/04/2010 16:27               |                                 |
`------------------------------------------/                                 |
                               |                                             |
                               `--------------------------------------------*/

#include <lbcpp/lbcpp.h>
#include "InferenceData/ScoreSymmetricMatrix.h"
#include "InferenceData/CommonFeatureGenerators.h"
#include "Protein/Evaluation/ProteinEvaluationCallback.h"
#include "Protein/Evaluation/ProteinStatisticsCalculator.h"
#include "Protein/SecondaryStructureDictionary.h"
#include "Protein/Inference/Protein1DInferenceStep.h"
#include "Protein/Inference/ProteinBackboneBondSequenceInferenceStep.h"
#include "Protein/Inference/ProteinContactMapInferenceStep.h"
#include "Protein/Inference/ProteinTertiaryStructureInferenceStep.h"
#include "Protein/Inference/ProteinInference.h"
using namespace lbcpp;

extern void declareProteinClasses();

class IterativeScalarInferenceLearningCallback : public ScalarInferenceLearningCallback
{
public:
  IterativeScalarInferenceLearningCallback(LearnableAtomicInferencePtr step, IterationFunctionPtr learningRate, bool normalizeLearningRate = true)
    : ScalarInferenceLearningCallback(step), lossValue(T("Loss")), learningRate(learningRate), normalizeLearningRate(normalizeLearningRate) {}

  virtual void finishInferencesCallback()
  {
    std::cout << step->getName() << " Epoch " << epoch << ", " << step->getParameters()->l0norm() << " parameters, L2 = " << String(step->getParameters()->l2norm(), 3) << std::endl;
    if (lossValue.getCount())
    {
      std::cout << lossValue.toString() << std::endl;
      lossValue.clear();
    }
    std::cout << std::endl;
  }

protected:
  ScalarVariableMean lossValue;
  IterationFunctionPtr learningRate;
  bool normalizeLearningRate;

  double computeAlpha() const
  {
    double res = 1.0;
    if (learningRate)
      res *= learningRate->compute(epoch);
    if (normalizeLearningRate && inputSize.getMean())
      res /= inputSize.getMean();
    return res;
  }

  void applyRegularizer(DenseVectorPtr parameters, ScalarVectorFunctionPtr regularizer, double alpha)
  {
    if (regularizer)
    {
      regularizer->computeGradient(parameters)->addWeightedTo(parameters, - alpha);
      step->validateParametersChange();
    }
  }
};

class IterativeDelayedScalarInferenceLearningCallback : public IterativeScalarInferenceLearningCallback
{
public:
  IterativeDelayedScalarInferenceLearningCallback(LearnableAtomicInferencePtr step, IterationFunctionPtr learningRate, bool normalizeLearningRate = true)
    : IterativeScalarInferenceLearningCallback(step, learningRate, normalizeLearningRate) {}

protected:
  std::vector< std::pair<FeatureGeneratorPtr, ScalarFunctionPtr> > examples;

  void processExample(FeatureGeneratorPtr features, ScalarFunctionPtr exampleLoss)
  {
    DenseVectorPtr parameters = step->getParameters();
    double alpha = computeAlpha();
    double prediction = features->dotProduct(parameters);
    double loss = exampleLoss->computeDerivative(prediction);
    lossValue.push(loss);
    features->addWeightedTo(parameters, - alpha * loss);
    step->validateParametersChange();
  }
};

class LocalRandomizedScalarLinearInferenceLearningCallback : public IterativeDelayedScalarInferenceLearningCallback
{
public:
  LocalRandomizedScalarLinearInferenceLearningCallback(LearnableAtomicInferencePtr step, IterationFunctionPtr learningRate, ScalarVectorFunctionPtr regularizer = ScalarVectorFunctionPtr(), bool normalizeLearningRate = true)
    : IterativeDelayedScalarInferenceLearningCallback(step, learningRate, normalizeLearningRate), regularizer(regularizer) {}

  virtual size_t postInferenceCallback(size_t epoch, FeatureGeneratorPtr features, double prediction, ScalarFunctionPtr exampleLoss)
  {
    updateInputSize(features);

    enum {randomizationSize = 10000};

    examples.push_back(std::make_pair(features, exampleLoss));
    if (examples.size() < 10000)
      return 0;

    std::vector<size_t> order;
    RandomGenerator::getInstance().sampleOrder(examples.size(), order);
    for (size_t i = 0; i < order.size(); ++i)
      processExample(examples[order[i]].first, examples[order[i]].second);
    applyRegularizer(step->getParameters(), regularizer, computeAlpha() * (double)examples.size());
    examples.clear();
    return order.size();
  }

  virtual void finishInferencesCallback()
  {
    std::cout << "Epoch " << epoch << ", " << step->getParameters()->l0norm() << " parameters, L2 = " << step->getParameters()->l2norm() << std::endl;
  }

protected:
  ScalarVectorFunctionPtr regularizer;
};

class PerEpisodeRandomizedLinearInferenceLearningCallback : public IterativeDelayedScalarInferenceLearningCallback
{
public:
  PerEpisodeRandomizedLinearInferenceLearningCallback(LearnableAtomicInferencePtr step, IterationFunctionPtr learningRate, ScalarVectorFunctionPtr regularizer = ScalarVectorFunctionPtr(), bool normalizeLearningRate = true)
    : IterativeDelayedScalarInferenceLearningCallback(step, learningRate, normalizeLearningRate), regularizer(regularizer) {}

  virtual size_t postInferenceCallback(size_t epoch, FeatureGeneratorPtr features, double prediction, ScalarFunctionPtr exampleLoss)
  {
    //if (RandomGenerator::getInstance().sampleBool(0.95))
    //  return 0; //reject 95% of examples
    if (exampleLoss->compute(1.0) > exampleLoss->compute(-1.0) && RandomGenerator::getInstance().sampleBool(0.8))
      return 0; // reject 80% of negative examples

    updateInputSize(features);
    examples.push_back(std::make_pair(features, exampleLoss));
    return 0;
  }

  virtual size_t postEpisodeCallback()
  {
    std::vector<size_t> order;
    RandomGenerator::getInstance().sampleOrder(examples.size(), order);
    for (size_t i = 0; i < order.size(); ++i)
      processExample(examples[order[i]].first, examples[order[i]].second);
    applyRegularizer(step->getParameters(), regularizer, computeAlpha() * (double)examples.size());
    examples.clear();
    return order.size();
  }

protected:
  ScalarVectorFunctionPtr regularizer;
};

class PerEpisodeScalarLinearInferenceLearningCallback : public IterativeScalarInferenceLearningCallback
{
public:
  PerEpisodeScalarLinearInferenceLearningCallback(LearnableAtomicInferencePtr step, IterationFunctionPtr learningRate, ScalarVectorFunctionPtr regularizer = ScalarVectorFunctionPtr(), bool normalizeLearningRate = true)
    : IterativeScalarInferenceLearningCallback(step, learningRate, normalizeLearningRate), regularizer(regularizer), examplesCount(0), updateNumber(0) {}

  virtual size_t postInferenceCallback(size_t epoch, FeatureGeneratorPtr features, double prediction, ScalarFunctionPtr exampleLoss)
  {
    bool isNegativeExample = exampleLoss->compute(1.0) > exampleLoss->compute(-1.0);
    if (isNegativeExample && RandomGenerator::getInstance().sampleBool(0.8))
      return 0; // reject 80% of negative examples
    double importance = 1.0;//isNegativeExample ? 0.1 : 1.0;

    updateInputSize(features);
    DenseVectorPtr parameters = step->getParameters();
    if (!gradientAccumulator)
      gradientAccumulator = new DenseVector(parameters->getDictionary());
  //  if (features->l2norm() > 50)
  //    std::cout << "Features: " << features->l0norm() << " " << features->l2norm() << " prediction = " << prediction << " loss = " << exampleLoss->computeDerivative(prediction) << " importance = " << importance << std::endl;
    features->addWeightedTo(gradientAccumulator, importance * exampleLoss->computeDerivative(prediction));
   // if (gradientAccumulator->l2norm() > 100000)
   //   std::cout << "Gradient accumulator: " << gradientAccumulator->l0norm() << " " << gradientAccumulator->l2norm() << std::endl;
    ++examplesCount;

    if (examplesCount % 100 == 0)
      flushGradient();

    return 1;
  }

  void flushGradient()
  {
    if (gradientAccumulator)
    {
      double k = - computeAlpha();
      ++updateNumber;

      //std::cout << updateNumber << " Gradient accumulator: " << gradientAccumulator->l0norm() << " " << gradientAccumulator->l2norm() << std::endl;
      gradientAccumulator->addWeightedTo(step->getParameters(), k);
      applyRegularizer(step->getParameters(), regularizer, (double)examplesCount * computeAlpha());
      step->validateParametersChange();
      examplesCount = 0;
      gradientAccumulator = DenseVectorPtr();
    }
  }

  virtual size_t postEpisodeCallback()
  {
    flushGradient();
    return 0;
  }

private:
  DenseVectorPtr gradientAccumulator;
  ScalarVectorFunctionPtr regularizer;
  size_t examplesCount;
  size_t updateNumber;
};

class MyInferenceLearnerCallback : public InferenceLearnerCallback
{
public:
  MyInferenceLearnerCallback(ObjectContainerPtr trainingData, ObjectContainerPtr testingData, bool useCacheOnTestingData = true)
    : trainingData(trainingData), testingData(testingData), startingTime(Time::getMillisecondCounter())
  {
    if (useCacheOnTestingData)
      cache = new InferenceResultCache();
  }

  virtual InferenceContextPtr createContext()
    {return singleThreadedInferenceContext();}
  
  virtual InferenceCallbackPtr createLearningCallback(LearnableAtomicInferencePtr step, InferencePtr parentStep)
  {
    if (parentStep.dynamicCast<ProteinContactMapInferenceStep>())
    {
      LearnableAtomicInferencePtr linearInference = step.dynamicCast<LearnableAtomicInference>();
      jassert(linearInference);
      double l2regularizer = 0;//.0001;
      return new PerEpisodeRandomizedLinearInferenceLearningCallback(linearInference,
          constantIterationFunction(2.0),//invLinearIterationFunction(2, 2000000),
          l2regularizer ? sumOfSquaresFunction(l2regularizer) : ScalarVectorFunctionPtr());
    }
    return InferenceCallbackPtr();
  }
  
  virtual double getProbabilityToCreateAnExample(InferenceStackPtr stack, ObjectPtr input, ObjectPtr supervision)
  {
    String inferenceStepName = stack->getInference(1)->getName();
    if (inferenceStepName == T("Init Step"))
      return 0.0;
    if (inferenceStepName == T("CA Update Pass"))
    {
      //RefineCAlphaPositionsInferenceStepPtr step = stack->getParentInference().dynamicCast<RefineCAlphaPositionsInferenceStep>();
      return 0.01;
    }

    if (inferenceStepName.startsWith(T("RR")))
    {
      ScalarFunctionPtr loss = supervision.dynamicCast<ScalarFunction>();
      jassert(loss);
      return loss->compute(0.0) < loss->compute(1.0)
        ? 0.05 // 5% probability for negative residue-residue contact examples
        : 1.0; // 100% probability for positive contacts
    }

    if (inferenceStepName.startsWith(T("DR")))
    {
      LabelPtr label = supervision.dynamicCast<Label>();
      jassert(label);
      return label->getIndex() == 1 ? 1.0 : 0.2; // 20% probability for negative disorder examples
    }
    return 1.0;
  }

  virtual ClassifierPtr createClassifier(InferenceStackPtr stack, FeatureDictionaryPtr labels)
  {
    std::cout << "CreateClassifier for step " << stack->getInference(1)->getName() << std::endl;
    if (labels == BinaryClassificationDictionary::getInstance())
    {
      IterationFunctionPtr learningRate = invLinearIterationFunction(0.5, 250000);
      GradientBasedLearnerPtr learner = stochasticDescentLearner(learningRate);  
      GradientBasedBinaryClassifierPtr classifier = linearSVMBinaryClassifier(learner, labels);
      classifier->setL2Regularizer(0.01);
      return classifier;
    }
    else
    {
      IterationFunctionPtr learningRate = invLinearIterationFunction(2.0, 250000);
      GradientBasedLearnerPtr learner = stochasticDescentLearner(learningRate);  
      return maximumEntropyClassifier(learner, labels, 20.0);
    }
  }

  virtual RegressorPtr createRegressor(InferenceStackPtr stack)
  {
    String inferenceStepName = stack->getInference(1)->getName();
      
    std::cout << "CreateRegressor for step " << inferenceStepName << std::endl;
    static const double regularizer = 0.0;

    IterationFunctionPtr learningRate;
    if (inferenceStepName.startsWith(T("BBB")))
      learningRate = constantIterationFunction(0.1);
    else if (inferenceStepName.startsWith(T("CA")))
      learningRate = constantIterationFunction(0.5);
    else if (inferenceStepName.startsWith(T("TS")))
      learningRate = constantIterationFunction(0.0001);
    else if (inferenceStepName.startsWith(T("RR")))
      learningRate = invLinearIterationFunction(0.5, 250000);
    else
      learningRate = invLinearIterationFunction(0.5, 150000);

    GradientBasedLearnerPtr learner = stochasticDescentLearner(learningRate);  
    return generalizedLinearRegressor(learner, regularizer);
  }

  virtual void preLearningIterationCallback(size_t iterationNumber)
    {std::cout << std::endl << " ================== ITERATION " << iterationNumber << " ================== " << (Time::getMillisecondCounter() - startingTime) / 1000.0 << " s" <<  std::endl;}

  // returns false if learning should stop
  virtual bool postLearningIterationCallback(InferencePtr inference, size_t iterationNumber)
  {
    InferenceContextPtr validationContext = createContext();
    ProteinEvaluationCallbackPtr evaluation = new ProteinEvaluationCallback();
    validationContext->appendCallback(evaluation);
    if (cache)
      validationContext->appendCallback(cacheInferenceCallback(cache, inference));

    juce::uint32 startTime = Time::getMillisecondCounter();
    validationContext->runWithSupervisedExamples(inference, trainingData);
    double length = (Time::getMillisecondCounter() - startTime) / 1000.0;
    std::cout << "Train evaluation time: " << length << "s" << std::endl;
    std::cout << "Train evaluation: " << evaluation->toString() << std::endl;
    //double trainRmse = 

    static double bestTrainAcc = 0.0;
    double trainAcc = evaluation->getDefaultScoreForTarget(T("ResidueResidueContactMatrix8Ca"));
    if (trainAcc > bestTrainAcc)
      bestTrainAcc = trainAcc;
    std::cout << "Best Train F1: " << String(bestTrainAcc * 100.0, 2) << "%" << std::endl;


    validationContext->runWithSupervisedExamples(inference, testingData);
    std::cout << "Test evaluation: " << evaluation->toString() << std::endl;

    static double bestTestAcc = 0.0;
    double testAcc = evaluation->getDefaultScoreForTarget(T("ResidueResidueContactMatrix8Ca"));
    if (testAcc > bestTestAcc)
      bestTestAcc = testAcc;
    std::cout << "Best Test F1: " << String(bestTestAcc * 100.0, 2) << "%" << std::endl;

    /*double testRmse = evaluation->getPSSMRootMeanSquareError();

    if (trainRmse < bestTrainRmse)
    {
      bestTrainRmse = trainRmse;
      bestTestRmse = testRmse;
    }*/

    // stopping criterion
    return iterationNumber < 50;
  }

  virtual void preLearningStepCallback(InferencePtr step)
  {
    String passName = step->getName();
    std::cout << std::endl << "=====================================================" << std::endl;
    std::cout << "======= LEARNING PASS " << passName << " ==========" << (Time::getMillisecondCounter() - startingTime) / 1000 << " s" << std::endl;
    std::cout << "=====================================================" << std::endl;
    //bestTrainRmse = bestTestRmse = DBL_MAX;
  }

  virtual void postLearningStepCallback(InferencePtr step)
  {
    //std::cout << "Best Train RMSE: " << bestTrainRmse << std::endl;
    //std::cout << "Best Test RMSE: " << bestTestRmse << std::endl;
  }

private:
  ObjectContainerPtr trainingData;
  ObjectContainerPtr testingData;
  InferenceResultCachePtr cache;
  juce::uint32 startingTime;

//  double bestTrainRmse, bestTestRmse;
};

ObjectContainerPtr loadProteins(const File& directory, size_t maxCount = 0)
{
  ObjectStreamPtr proteinsStream = directoryObjectStream(directory, T("*.protein"));
#ifdef JUCE_DEBUG
  ObjectContainerPtr res = proteinsStream->load(maxCount ? maxCount : 7)->randomize();
#else
  ObjectContainerPtr res = proteinsStream->load(maxCount)->randomize();
#endif
  for (size_t i = 0; i < res->size(); ++i)
  {
    ProteinPtr protein = res->getAndCast<Protein>(i);
    jassert(protein);
    protein->computeMissingFields();
  }
  return res;
}

class MyResidueFeatures : public ProteinResidueFeatures
{
public:
  virtual featureGenerator compute(ProteinPtr protein, size_t position)
  {
    featureCall(0) computePSSMEntropy(protein, position);    
  }

  FeatureGeneratorPtr computePSSMEntropy(ProteinPtr protein, size_t position)
  {
    ScoreVectorSequencePtr pssm = protein->getPositionSpecificScoringMatrix();
    if (!pssm)
      return FeatureGeneratorPtr();

    double entropy = 0.0;
    for (size_t i = 0; i < pssm->getNumScores(); ++i)
    {
      double probability = pssm->getScore(position, i);
      if (probability > 0.00001)
        entropy -= probability * log2(probability);
    }
    return numberLogFeatures(entropy, 1);
  }
};

class MyResiduePairFeatures : public ProteinResiduePairFeatures
{
public:
  featureGenerator pssmProductFeatures(ScoreVectorSequencePtr pssm, int firstPosition, int secondPosition)
  {
    size_t n = pssm->size();
    if (firstPosition < 0 || firstPosition >= (int)n || secondPosition < 0 || secondPosition >= (int)n)
      return;

    for (size_t i = 0; i < pssm->getNumScores(); ++i)
    {
      double s = pssm->getScore(firstPosition, i) * pssm->getScore(secondPosition, i);
      if (s)
        featureSense(i, s);
    }
  }

  featureGenerator pssmWindowProduct(ScoreVectorSequencePtr pssm, size_t firstPosition, size_t secondPosition, int pssmProductHalfWindowSize)
  {
    for (int delta1 = -pssmProductHalfWindowSize; delta1 <= pssmProductHalfWindowSize; ++delta1)
      featureScope(delta1 + pssmProductHalfWindowSize)
        for (int delta2 = -pssmProductHalfWindowSize; delta2 <= pssmProductHalfWindowSize; ++delta2)
          featureCall(delta2 + pssmProductHalfWindowSize)
            pssmProductFeatures(pssm, (int)firstPosition + delta1, (int)secondPosition + delta2);
  }

  featureGenerator structureNeighborhoodFeatures(ProteinPtr protein, ScoreSymmetricMatrixPtr contactMap, size_t position)
  {
    size_t n = contactMap->getDimension();
    size_t numContacts = 0;
    for (size_t i = 0; i < n; ++i)
      if (contactMap->hasScore(position, i) && i != position)
      {
        if (contactMap->getScore(position, i) > 0.5)
        {
          featureSense(protein->getAminoAcidSequence()->getIndex(i));
          ++numContacts;
        }
      }
    featureCall(0) numberLogFeatures((double)numContacts);
  }

  featureGenerator structureFeatures(ProteinPtr protein, ScoreSymmetricMatrixPtr contactMap, size_t firstPosition, size_t secondPosition)
  {
    featureCall(0) structureNeighborhoodFeatures(protein, contactMap, firstPosition);
    featureCall(1) structureNeighborhoodFeatures(protein, contactMap, secondPosition);
  }

  FeatureGeneratorPtr prolongedDirectionContactFeatures(ScoreSymmetricMatrixPtr contactMap, size_t firstPosition, size_t secondPosition, int delta1, int delta2)
  {
    int dim = (int)contactMap->getDimension();
    size_t count;
    for (count = 0; true; ++count)
    {
      int p1 = (int)firstPosition + delta1 * count;
      int p2 = (int)secondPosition + delta2 * count;
      if (p1 < 0 || p2 < 0 || p1 >= dim || p2 >= dim)
        break;
      if (contactMap->getScore(p1, p2) <= 0.5)
        break;
    }
    return numberLogFeatures(count, 5);
  }

  featureGenerator prolongedContactFeatures(ProteinPtr protein, ScoreSymmetricMatrixPtr contactMap, size_t firstPosition, size_t secondPosition)
  {
    featureCall(0) prolongedDirectionContactFeatures(contactMap, firstPosition, secondPosition, -1, -1);
    featureCall(1) prolongedDirectionContactFeatures(contactMap, firstPosition, secondPosition, -1, +1);
    featureCall(2) prolongedDirectionContactFeatures(contactMap, firstPosition, secondPosition, +1, +1);
    featureCall(3) prolongedDirectionContactFeatures(contactMap, firstPosition, secondPosition, +1, -1);
  }

  virtual featureGenerator compute(ProteinPtr protein, size_t firstPosition, size_t secondPosition)
  {
    featureSense("unit");

    ScoreSymmetricMatrixPtr contactMap = protein->getResidueResidueContactMatrix8Ca();

    ScoreVectorSequencePtr pssm = protein->getPositionSpecificScoringMatrix();

    featureCall(1) pssmWindowProduct(pssm, firstPosition, secondPosition, 1);
    
    if (contactMap)
    {
      //featureCall(2) structureFeatures(protein, contactMap, firstPosition, secondPosition);
      featureCall(3) prolongedContactFeatures(protein, contactMap, firstPosition, secondPosition);
    }
     
    //featureCall(1)
//      pssmProductFeatures(protein->getPositionSpecificScoringMatrix(), firstPosition, secondPosition);

    featureScope(0)
    {
      LabelSequencePtr aminoAcidSequence = protein->getAminoAcidSequence();
      featureScope(aminoAcidSequence->getIndex(firstPosition))
        featureSense(aminoAcidSequence->getIndex(secondPosition));
    }
  }
};

int main(int argc, char** argv)
{
  declareProteinClasses();

  File modelDirectory(T("C:\\Projets\\LBC++\\projects\\temp\\Models\\RR.model"));

  File smallPDBDirectory(T("C:\\Projets\\LBC++\\projects\\temp\\SmallPDB\\protein"));
  ObjectContainerPtr smallPDBProteins = loadProteins(smallPDBDirectory);
  std::cout << "SmallPDB " << ProteinStatisticsCalculator::computeStatistics(smallPDBProteins) << std::endl;
  smallPDBProteins = smallPDBProteins->apply(new ObjectToObjectPairFunction());

  //proteins = proteins->apply(new ProteinToInputOutputPair());

  ObjectContainerPtr trainingData = smallPDBProteins->size() >= 7 ? smallPDBProteins->invFold(0,7) : smallPDBProteins;
  ObjectContainerPtr testingData = smallPDBProteins->size() >= 7 ? smallPDBProteins->fold(0,7) : smallPDBProteins;

  std::cout << trainingData->size() << " Training Proteins "
            << testingData->size() << " Testing Proteins" << std::endl;


  /*
  ** Creation of the feature function
  */
  CompositeProteinResidueFeaturesPtr featureFunction = new CompositeProteinResidueFeatures();

  //featureFunction->addSubFeatures(proteinUnitResidueFeature());
  //featureFunction->addSubFeatures(proteinPositionIndexResidueFeature()); // DEBUG !!

  //featureFunction->addSubFeatures(proteinSequenceWindowFeatures(T("AminoAcidSequence"), 8, 8, true));
  featureFunction->addSubFeatures(proteinSequenceWindowFeatures(T("PositionSpecificScoringMatrix"), 8, 8, true));
  /*featureFunction->addSubFeatures(proteinSequenceWindowFeatures(T("SecondaryStructureSequence"), 5, 5, true));
  featureFunction->addSubFeatures(proteinSequenceWindowFeatures(T("DSSPSecondaryStructureSequence"), 5, 5, true));
  featureFunction->addSubFeatures(proteinSequenceWindowFeatures(T("SolventAccessibilityThreshold20"), 5, 5, true));
  featureFunction->addSubFeatures(proteinSequenceWindowFeatures(T("DisorderProbabilitySequence"), 5, 5, true));
  featureFunction->addSubFeatures(proteinSequenceWindowFeatures(T("BackboneBondSequence"), 5, 5, true));*/

  // New features :
  //featureFunction->addSubFeatures(proteinPositionFeatures());
  //featureFunction->addSubFeatures(proteinLengthFeatures());
  //featureFunction->addSubFeatures(proteinSegmentConjunctionFeatures(T("SecondaryStructureSequence"), 5));

  //featureFunction->addSubFeatures(new MyResidueFeatures());

  CompositeProteinResiduePairFeaturesPtr pairFeatureFunction = new CompositeProteinResiduePairFeatures();

  // global
  //pairFeatureFunction->addSubFeatures(proteinGlobalToResiduePairFeatures(proteinLengthFeatures(3)));
  pairFeatureFunction->addSubFeatures(proteinGlobalToResiduePairFeatures(proteinGlobalCompositionFeatures(T("AminoAcidSequence"))));
  pairFeatureFunction->addSubFeatures(proteinGlobalToResiduePairFeatures(proteinGlobalCompositionFeatures(T("PositionSpecificScoringMatrix"))));

  // point features
  pairFeatureFunction->addSubFeatures(proteinPointResiduePairFeatures(featureFunction));

  // pair features
  pairFeatureFunction->addSubFeatures(separationLengthResiduePairFeatures());
  //pairFeatureFunction->addSubFeatures(proteinCentralCompositionResiduePairFeatures(T("AminoAcidSequence")));
  //pairFeatureFunction->addSubFeatures(proteinCentralCompositionResiduePairFeatures(T("PositionSpecificScoringMatrix")));

  pairFeatureFunction->addSubFeatures(new MyResiduePairFeatures());

  CompositeProteinResiduePairFeaturesPtr pairFeatureFunction2 = new CompositeProteinResiduePairFeatures();
  pairFeatureFunction2->addSubFeatures(conjunctionResiduePairFeatures(aaCategoryResiduePairConjunction, pairFeatureFunction));
  pairFeatureFunction2->addSubFeatures(conjunctionResiduePairFeatures(proteinLengthResiduePairConjunction, pairFeatureFunction));

  //pairFeatureFunction->addSubFeatures(new TriDimProteinResiduePairFeatures());
  //pairFeatureFunction->addSubFeatures(proteinPositionIndexResiduePairFeature());

  /*
  ** Creation of the inference 
  */
  ProteinInferencePtr proteinInference = new ProteinInference();
  proteinInference->setPDBDebugDirectory(File(T("C:\\Projets\\LBC++\\projects\\temp\\pdbs")));

  for (size_t i = 0; i < 2; ++i)
  {
    Protein2DInferenceStepPtr step = new ProteinContactMapInferenceStep(T("RR Pass ") + lbcpp::toString(i),
                                                       pairFeatureFunction2, T("ResidueResidueContactMatrix8Ca"));
    proteinInference->appendStep(step);
    
#if 0
      step = new ProteinSequenceLabelingInferenceStep(T("SS3 Pass ") + lbcpp::toString(i), featureFunction, /*T("SecondaryStructureProbabilities"), */T("SecondaryStructureSequence"));
      proteinInference->appendStep(step);
      step = new ProteinSequenceLabelingInferenceStep(T("DR Pass ") + lbcpp::toString(i), featureFunction, T("DisorderProbabilitySequence"), T("DisorderSequence"));
      proteinInference->appendStep(step);
      step = new ProteinSequenceLabelingInferenceStep(T("SA Pass ") + lbcpp::toString(i), featureFunction, T("SolventAccessibilityThreshold20"));
      proteinInference->appendStep(step);
      step = new ProteinBackboneBondSequenceInferenceStep(T("BBB Pass ") + lbcpp::toString(i), featureFunction);
      proteinInference->appendStep(step);
#endif // 0
  }
  //std::cout << "Inference: " << proteinInference->toString() << std::endl;

  /*
  ** Learning
  */
  InferenceLearnerCallbackPtr callback = new MyInferenceLearnerCallback(trainingData, testingData, false);
  //InferenceLearnerPtr learner = stepByStepDeterministicSimulationLearner(callback, true);//, modelDirectory, true);
  InferenceLearnerPtr learner = globalSimulationLearner(callback);
  learner->train(proteinInference, trainingData);

  /*
  ** Evaluation
  *
  InferenceContextPtr validationContext = singleThreadedInferenceContext();
  ProteinEvaluationCallbackPtr evaluation = new ProteinEvaluationCallback();
  validationContext->appendCallback(evaluation);

  validationContext->runWithSupervisedExamples(proteinInference, trainingData);
  std::cout << "Train evaluation: " << evaluation->toString() << std::endl;

  validationContext->runWithSupervisedExamples(proteinInference, testingData);
  std::cout << "Test evaluation: " << evaluation->toString() << std::endl;
  */
  return 0;
}
